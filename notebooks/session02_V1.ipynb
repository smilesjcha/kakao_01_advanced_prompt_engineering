{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3527062",
   "metadata": {},
   "source": [
    "# Sessionâ€¯2 â€” Prompt Engineering ì‹¤ìŠµ (V1)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ *ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§* ì‹¤ìŠµìš©ìœ¼ë¡œ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.  \n",
    "- **ë¬¸ì œ ì •ì˜ â†’ V0 â†’ V1 â†’ V2** ìˆœìœ¼ë¡œ ë‹¨ê³„ë³„ ê°œì„  ê³¼ì •ì„ ì²´í—˜í•©ë‹ˆë‹¤.  \n",
    "- ì˜¤ì§ **`gptâ€‘4oâ€‘mini`** ëª¨ë¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
    "- ì‹¤ì œ íšŒì‚¬ ë°ì´í„° ëŒ€ì‹  *ìƒ˜í”Œ* ì‹œë‚˜ë¦¬ì˜¤ 3ì¢…(`order_delivery`, `refund`, `account_login`)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
    "- ê° ë²„ì „ë³„ **ì‘ë‹µ ë‚´ìš©Â·ì§€ì—° ì‹œê°„Â·ë¹„ìš©**ì„ ë¹„êµí•´ ë³´ì„¸ìš”.\n",
    "\n",
    "> ì‹¤ìŠµ ê²°ê³¼ëŠ” ê°œì¸ë³„ë¡œ V0.xÂ ~Â V0.3 ë“±ì˜ ë²„ì „ì„ ì¶”ê°€í•˜ë©° ììœ ë¡­ê²Œ ë°œì „ì‹œí‚¤ë©´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5142eb0",
   "metadata": {},
   "source": [
    "## íŒ¨í‚¤ì§€ ì„¤ì¹˜ (Colab ë˜ëŠ” ë¡œì»¬)\n",
    "\n",
    "í•„ìš”í•œ ê²½ìš° ì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca2fc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jinja2==3.1.5 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (3.1.5)\n",
      "Requirement already satisfied: numpy==2.2.3 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: openai==1.65.5 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 3)) (1.65.5)\n",
      "Collecting langfuse==2.60.5 (from -r ../requirements.txt (line 4))\n",
      "  Obtaining dependency information for langfuse==2.60.5 from https://files.pythonhosted.org/packages/e9/04/8d69112a6b24431bfdb257a2a394f0ab036e5be5dcf4cb3b15db43b367f6/langfuse-2.60.5-py3-none-any.whl.metadata\n",
      "  Downloading langfuse-2.60.5-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: openpyxl==3.1.5 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 5)) (3.1.5)\n",
      "Requirement already satisfied: pandas==2.2.3 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 6)) (2.2.3)\n",
      "Requirement already satisfied: notion-client==2.3.0 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 7)) (2.3.0)\n",
      "Requirement already satisfied: xlsxwriter==3.2.0 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: aiohttp==3.9.1 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 9)) (3.9.1)\n",
      "Requirement already satisfied: nest_asyncio==1.5.7 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 10)) (1.5.7)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2==3.1.5->-r ../requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (2.11.5)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/homebrew/lib/python3.10/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (2.2.1)\n",
      "Requirement already satisfied: idna<4.0,>=3.7 in /opt/homebrew/lib/python3.10/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: packaging<25.0,>=23.2 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (24.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/lib/python3.10/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (2.32.4)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /opt/homebrew/lib/python3.10/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (1.17.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/homebrew/lib/python3.10/site-packages (from openpyxl==3.1.5->-r ../requirements.txt (line 5)) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from pandas==2.2.3->-r ../requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas==2.2.3->-r ../requirements.txt (line 6)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.10/site-packages (from pandas==2.2.3->-r ../requirements.txt (line 6)) (2025.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (25.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (6.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (1.20.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (1.7.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (4.0.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from anyio<5,>=3.5.0->openai==1.65.5->-r ../requirements.txt (line 3)) (1.2.1)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.65.5->-r ../requirements.txt (line 3)) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.65.5->-r ../requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.65.5->-r ../requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.65.5->-r ../requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.65.5->-r ../requirements.txt (line 3)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.65.5->-r ../requirements.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r ../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests<3,>=2->langfuse==2.60.5->-r ../requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests<3,>=2->langfuse==2.60.5->-r ../requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /opt/homebrew/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp==3.9.1->-r ../requirements.txt (line 9)) (0.3.2)\n",
      "Downloading langfuse-2.60.5-py3-none-any.whl (275 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m275.4/275.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langfuse\n",
      "  Attempting uninstall: langfuse\n",
      "    Found existing installation: langfuse 2.59.7\n",
      "    Uninstalling langfuse-2.59.7:\n",
      "      Successfully uninstalled langfuse-2.59.7\n",
      "Successfully installed langfuse-2.60.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b33eb",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì • ë° ê³µí†µ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2c7a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, asyncio, time\n",
    "import nest_asyncio, pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langfuse import Langfuse\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "USE_STUB = OPENAI_API_KEY is None\n",
    "langfuse = Langfuse()\n",
    "\n",
    "if USE_STUB:\n",
    "    print(\"ğŸ”§  Stub ëª¨ë“œ: OPENAI_API_KEY ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‹¤ì œ API í˜¸ì¶œ ëŒ€ì‹  ë”ë¯¸ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    from langfuse.openai import AsyncOpenAI\n",
    "    client = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ê°€ê²©(USD / token)\n",
    "PRICING = {\"input\": 0.15/1_000_000, \"output\": 0.60/1_000_000}\n",
    "\n",
    "async def call_openai(system_prompt: str, user_prompt: str, model: str = \"gpt-4o-mini\"):\n",
    "    start = time.perf_counter_ns()\n",
    "    if USE_STUB:\n",
    "        await asyncio.sleep(0.05)  # ì§€ì—° ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜\n",
    "        answer = f\"[STUB] '{user_prompt[:25]}...' ì— ëŒ€í•œ ì˜ˆì‹œ ì‘ë‹µ\"\n",
    "        prompt_tokens = len(system_prompt.split()) + len(user_prompt.split())\n",
    "        completion_tokens = 120\n",
    "    else:\n",
    "        resp = await client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "        )\n",
    "        answer = resp.choices[0].message.content.strip()\n",
    "        usage = resp.usage\n",
    "        prompt_tokens = usage.prompt_tokens\n",
    "        completion_tokens = usage.completion_tokens\n",
    "    latency_ms = (time.perf_counter_ns() - start) / 1_000_000\n",
    "    cost = prompt_tokens * PRICING[\"input\"] + completion_tokens * PRICING[\"output\"]\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"latency_ms\": latency_ms,\n",
    "        \"prompt_tokens\": prompt_tokens,\n",
    "        \"completion_tokens\": completion_tokens,\n",
    "        \"usd_cost\": cost,\n",
    "    }\n",
    "\n",
    "async def run_version(df: pd.DataFrame, version_name: str, build_system_prompt):\n",
    "    tasks = []\n",
    "    for _, row in df.iterrows():\n",
    "        tasks.append(call_openai(build_system_prompt(row), row['question']))\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    # ê²°ê³¼ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³‘í•©\n",
    "    for idx, res in enumerate(results):\n",
    "        for key, val in res.items():\n",
    "            df.loc[idx, f\"{version_name}_{key}\"] = val\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc54e59",
   "metadata": {},
   "source": [
    "## ì˜ˆì‹œ ì‹œë‚˜ë¦¬ì˜¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b45cc54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>ì£¼ë¬¸í•œ ìƒí’ˆì´ ë°°ì†¡ ì˜ˆì •ì¼ì„ ì§€ë‚¬ëŠ”ë° ì•„ì§ ë„ì°©í•˜ì§€ ì•Šì•˜ì–´ìš”. ì–´ë–»ê²Œ í™•ì¸í•˜ë‚˜ìš”?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>ë°˜í’ˆ ì‹ ì²­ì„ í–ˆëŠ”ë° í™˜ë¶ˆ ì²˜ë¦¬ê°€ ì–¸ì œ ì™„ë£Œë˜ë‚˜ìš”?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>ë¡œê·¸ì¸ ì‹œë„ ì‹œ 2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆë‚˜ìš”?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario                                       question\n",
       "0  order_delivery  ì£¼ë¬¸í•œ ìƒí’ˆì´ ë°°ì†¡ ì˜ˆì •ì¼ì„ ì§€ë‚¬ëŠ”ë° ì•„ì§ ë„ì°©í•˜ì§€ ì•Šì•˜ì–´ìš”. ì–´ë–»ê²Œ í™•ì¸í•˜ë‚˜ìš”?\n",
       "1          refund                    ë°˜í’ˆ ì‹ ì²­ì„ í–ˆëŠ”ë° í™˜ë¶ˆ ì²˜ë¦¬ê°€ ì–¸ì œ ì™„ë£Œë˜ë‚˜ìš”?\n",
       "2   account_login      ë¡œê·¸ì¸ ì‹œë„ ì‹œ 2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆë‚˜ìš”?"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios = [\n",
    "    {\"scenario\": \"order_delivery\", \"question\": \"ì£¼ë¬¸í•œ ìƒí’ˆì´ ë°°ì†¡ ì˜ˆì •ì¼ì„ ì§€ë‚¬ëŠ”ë° ì•„ì§ ë„ì°©í•˜ì§€ ì•Šì•˜ì–´ìš”. ì–´ë–»ê²Œ í™•ì¸í•˜ë‚˜ìš”?\"},\n",
    "    {\"scenario\": \"refund\", \"question\": \"ë°˜í’ˆ ì‹ ì²­ì„ í–ˆëŠ”ë° í™˜ë¶ˆ ì²˜ë¦¬ê°€ ì–¸ì œ ì™„ë£Œë˜ë‚˜ìš”?\"},\n",
    "    {\"scenario\": \"account_login\", \"question\": \"ë¡œê·¸ì¸ ì‹œë„ ì‹œ 2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆë‚˜ìš”?\"},\n",
    "]\n",
    "df = pd.DataFrame(scenarios)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1589f884",
   "metadata": {},
   "source": [
    "## V0.0 â€” Zeroâ€‘Shot (System Prompt ì—†ì´ ë°”ë¡œ ì§ˆë¬¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6ce598d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>V0_0_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>ì£¼ë¬¸í•œ ìƒí’ˆì´ ë°°ì†¡ ì˜ˆì •ì¼ì„ ì§€ë‚˜ë„ ë„ì°©í•˜ì§€ ì•Šì€ ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ í™•ì¸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>ë°˜í’ˆ ì‹ ì²­ í›„ í™˜ë¶ˆ ì²˜ë¦¬ ì™„ë£Œê¹Œì§€ ì†Œìš”ë˜ëŠ” ì‹œê°„ì€ ì£¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ìš”ì†Œì— ë”°ë¼ ë‹¬...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario                                        V0_0_answer\n",
       "0  order_delivery  ì£¼ë¬¸í•œ ìƒí’ˆì´ ë°°ì†¡ ì˜ˆì •ì¼ì„ ì§€ë‚˜ë„ ë„ì°©í•˜ì§€ ì•Šì€ ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ í™•ì¸...\n",
       "1          refund  ë°˜í’ˆ ì‹ ì²­ í›„ í™˜ë¶ˆ ì²˜ë¦¬ ì™„ë£Œê¹Œì§€ ì†Œìš”ë˜ëŠ” ì‹œê°„ì€ ì£¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ìš”ì†Œì— ë”°ë¼ ë‹¬...\n",
       "2   account_login  2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sys_prompt_v0_0(row):\n",
    "    return \"\"\n",
    "\n",
    "await run_version(df, \"V0_0\", sys_prompt_v0_0)\n",
    "df[['scenario', 'V0_0_answer']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80fcc52",
   "metadata": {},
   "source": [
    "## V0.1 â€” Persona + Tone + Clear Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eb01104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>V0_1_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”, ê³ ê°ë‹˜. ë°°ì†¡ ì˜ˆì •ì¼ì´ ì§€ë‚˜ë„ ìƒí’ˆì´ ë„ì°©í•˜ì§€ ì•Šì€ ì  ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>ê³ ê°ë‹˜, ë°˜í’ˆ ì‹ ì²­ í›„ í™˜ë¶ˆ ì²˜ë¦¬ì—ëŠ” ë³´í†µ 3-7ì¼ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤. ë°˜í’ˆ ìƒí’ˆì´ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”. 2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ë¡œ ì¸í•´ ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ë¨¼ì €, ì¸ì¦ ì½”ë“œê°€ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario                                        V0_1_answer\n",
       "0  order_delivery  ì•ˆë…•í•˜ì„¸ìš”, ê³ ê°ë‹˜. ë°°ì†¡ ì˜ˆì •ì¼ì´ ì§€ë‚˜ë„ ìƒí’ˆì´ ë„ì°©í•˜ì§€ ì•Šì€ ì  ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤. ...\n",
       "1          refund  ê³ ê°ë‹˜, ë°˜í’ˆ ì‹ ì²­ í›„ í™˜ë¶ˆ ì²˜ë¦¬ì—ëŠ” ë³´í†µ 3-7ì¼ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤. ë°˜í’ˆ ìƒí’ˆì´ ...\n",
       "2   account_login  ì•ˆë…•í•˜ì„¸ìš”. 2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ë¡œ ì¸í•´ ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ë¨¼ì €, ì¸ì¦ ì½”ë“œê°€ ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sys_prompt_v0_1(row):\n",
    "    return (\n",
    "        \"You are a calm and professional Korean CS chatbot for an eâ€‘commerce platform. \"\n",
    "        \"Answer politely in Korean, maximum 5 sentences.\"\n",
    "    )\n",
    "\n",
    "await run_version(df, \"V0_1\", sys_prompt_v0_1)\n",
    "df[['scenario','V0_1_answer']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306705c",
   "metadata": {},
   "source": [
    "## V0.2 â€” Fewâ€‘Shot + Chainâ€‘ofâ€‘Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e385730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>V0_2_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ì£¼ë¬¸í•˜ì‹  ìƒí’ˆì˜ ìš´ì†¡ì¥ ë²ˆí˜¸ë¥¼ í™•ì¸í•´ ì£¼ì‹œë©´ ë°°ì†¡ ìƒíƒœë¥¼ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>ë°˜í’ˆ ì‹ ì²­ í›„ í™˜ë¶ˆ ì²˜ë¦¬ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 3~5ì¼ ì†Œìš”ë©ë‹ˆë‹¤. ë°˜í’ˆ ìƒí’ˆì´ ë„ì°©í•˜ê³  ê²€...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ëŠ” ì£¼ë¡œ ì…ë ¥í•œ ì „í™”ë²ˆí˜¸ì™€ ì¸ì¦ ë°©ë²• ì„¤ì •ì˜ ë¶ˆì¼ì¹˜ í˜¹ì€ ì¼ì‹œì ì¸ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario                                        V0_2_answer\n",
       "0  order_delivery  ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ì£¼ë¬¸í•˜ì‹  ìƒí’ˆì˜ ìš´ì†¡ì¥ ë²ˆí˜¸ë¥¼ í™•ì¸í•´ ì£¼ì‹œë©´ ë°°ì†¡ ìƒíƒœë¥¼ ...\n",
       "1          refund  ë°˜í’ˆ ì‹ ì²­ í›„ í™˜ë¶ˆ ì²˜ë¦¬ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 3~5ì¼ ì†Œìš”ë©ë‹ˆë‹¤. ë°˜í’ˆ ìƒí’ˆì´ ë„ì°©í•˜ê³  ê²€...\n",
       "2   account_login  2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ëŠ” ì£¼ë¡œ ì…ë ¥í•œ ì „í™”ë²ˆí˜¸ì™€ ì¸ì¦ ë°©ë²• ì„¤ì •ì˜ ë¶ˆì¼ì¹˜ í˜¹ì€ ì¼ì‹œì ì¸ ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_examples = \"\"\"\n",
    "<example>\n",
    "[ê³ ê°] ì£¼ë¬¸í•œ ìƒí’ˆì´ ì•„ì§ ë„ì°©í•˜ì§€ ì•Šì•˜ì–´ìš”!\n",
    "[ì±—ë´‡] ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ìš´ì†¡ì¥ ë²ˆí˜¸ 123â€‘4567ì„ ì¡°íšŒí•´ ë³´ë‹ˆ í˜„ì¬ ë¬¼ë¥˜ì„¼í„°ì— ìˆìŠµë‹ˆë‹¤. 1~2ì¼ ë‚´ ë„ì°© ì˜ˆì •ì´ë©°, ì§€ì—° ì‹œ ë°”ë¡œ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
    "</example>\n",
    "\"\"\"\n",
    "\n",
    "def sys_prompt_v0_2(row):\n",
    "    return (\n",
    "        f\"{few_shot_examples}\\n\\n\"\n",
    "        \"You are a CS assistant. Think stepâ€‘byâ€‘step to figure out the cause internally, \"\n",
    "        \"but provide only the final concise answer in Korean (max 5 lines).\"\n",
    "    )\n",
    "\n",
    "await run_version(df, \"V0_2\", sys_prompt_v0_2)\n",
    "df[['scenario','V0_2_answer']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da1030",
   "metadata": {},
   "source": [
    "## ë²„ì „ë³„ ë¹„êµ (Latency & Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce880de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>V0_0_latency_ms</th>\n",
       "      <th>V0_0_usd_cost</th>\n",
       "      <th>V0_1_latency_ms</th>\n",
       "      <th>V0_1_usd_cost</th>\n",
       "      <th>V0_2_latency_ms</th>\n",
       "      <th>V0_2_usd_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>5201.338833</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>1545.340375</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>1634.396875</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>8404.851375</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>1648.630500</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1440.019500</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>5667.732541</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>2128.210834</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>3735.301250</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario  V0_0_latency_ms  V0_0_usd_cost  V0_1_latency_ms  \\\n",
       "0  order_delivery      5201.338833       0.000153      1545.340375   \n",
       "1          refund      8404.851375       0.000107      1648.630500   \n",
       "2   account_login      5667.732541       0.000199      2128.210834   \n",
       "\n",
       "   V0_1_usd_cost  V0_2_latency_ms  V0_2_usd_cost  \n",
       "0       0.000049      1634.396875       0.000072  \n",
       "1       0.000058      1440.019500       0.000050  \n",
       "2       0.000068      3735.301250       0.000066  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_cols = ['scenario']\n",
    "for v in ['V0_0','V0_1','V0_2']:\n",
    "    compare_cols += [f\"{v}_latency_ms\", f\"{v}_usd_cost\"]\n",
    "df[compare_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a01b92",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœï¸ ê°œì¸ ì‹¤ìŠµ ì˜ì—­\n",
    "\n",
    "ì•„ë˜ ë¹ˆ ì…€ì„ ë³µì‚¬í•˜ì—¬ **V0.1 ~ V0.3** ë“± ìì‹ ë§Œì˜ ë³€í˜•ì„ ì‹œë„í•´ ë³´ì„¸ìš”.  \n",
    "- ìƒˆë¡œìš´ System Promptë¥¼ ì„¤ê³„í•˜ê±°ë‚˜  \n",
    "- Fewâ€‘Shot ì˜ˆì‹œ ê°œìˆ˜ë¥¼ ëŠ˜ë¦¬ê±°ë‚˜  \n",
    "- ELI5, JSON í¬ë§· ë“± ì¶”ê°€ ìš”êµ¬ì‚¬í•­ì„ ë„£ì–´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ì—¬ê¸°ì— ê°œì¸ ì‹¤ìŠµ ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba01ef8",
   "metadata": {},
   "source": [
    "# ë ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84acbd8",
   "metadata": {},
   "source": [
    "## ì‘ì—…í•œ V1.0 Prompt Langfuseì— ë“±ë¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a75a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ë‹¹ì‹ ì€ 30ëŒ€ ì¤‘ë°˜ì˜ ìˆ™ë ¨ëœ ì „ììƒê±°ë˜ ë°°ì†¡ CS ë‹´ë‹¹ìì…ë‹ˆë‹¤.  \n",
      "  ë§íˆ¬ëŠ” ì°¨ë¶„í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”.  \n",
      "  \n",
      "  ### ë‚´ë¶€ ì‚¬ê³ (Chain-of-Thought) ê°€ì´ë“œ â€” ê³ ê°ì—ê²ŒëŠ” ë³´ì´ì§€ ì•Šë„ë¡!  \n",
      "  1. ì§ˆë¬¸ì—ì„œ ìš”êµ¬í•˜ëŠ” ì •ë³´ê°€ ì£¼ì†Œ ë³€ê²½/ë°°ì†¡ ì§€ì—°/ìš´ì†¡ì¥ ë“± ì–´ëŠ ìœ í˜•ì¸ì§€ ë¶„ë¥˜  \n",
      "  2. CSVë¡œ ì „ë‹¬ëœ ì£¼ë¬¸Â·ì£¼ì†ŒÂ·ë°°ì†¡ ìƒíƒœë¥¼ ë‹¨ê³„ë³„ë¡œ ì ê²€  \n",
      "  3. í•´ê²° ì ˆì°¨Â·ì˜ˆìƒ ì¼ì •Â·ì¬ë°œ ì•Œë¦¼ ë“±ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì •ë¦¬\n",
      "  \n",
      "  ### ìµœì¢… ì‘ë‹µ í˜•ì‹ â€” í•œêµ­ì–´ 120ë‹¨ì–´ ì´ë‚´  \n",
      "  â€¢ ê³ ê°ëª… + ì£¼ë¬¸Â·ìƒí’ˆÂ·ìƒíƒœ ìš”ì•½  \n",
      "  â€¢ ë‹¤ìŒ ì§„í–‰ ë‹¨ê³„ or ì¡°ì¹˜(ìˆ«ì ëª©ë¡ ì‚¬ìš©)  \n",
      "  â€¢ ë§ˆë¬´ë¦¬ ë¬¸êµ¬: â€œì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”.â€\n",
      "\n",
      "  ### ì§ˆë¬¸\n",
      "  {{question}}\n",
      "  \n",
      "  ### ê³ ê°Â·ì£¼ë¬¸ ì»¨í…ìŠ¤íŠ¸\n",
      "  ID: {{customer_id}}  ì´ë¦„: {{customer_name}}\n",
      "  ì£¼ë¬¸ë²ˆí˜¸: {{order_id}}  ìƒí’ˆ: {{product_name}}\n",
      "  ë°°ì†¡ìƒíƒœ: {{shipping_status}}  (ìµœê·¼ ì—…ë°ì´íŠ¸: {{last_update}})\n",
      "  íƒë°°ì‚¬: {{shipping_company}}  ì†¡ì¥: {{tracking_number}}\n",
      "  ê¸°ë³¸ì£¼ì†Œ: {{address_line1}}, {{city}} {{postal_code}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while fetching prompt 'order_delivery.v1_0-label:production': status_code: 404, body: {'message': \"Prompt not found: 'order_delivery.v1_0' with label 'production'\", 'error': 'LangfuseNotFoundError'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prompt created (v1.0)\n",
      "ğŸ‘€ Langfuse UI â–¸ Prompts â–¸ order_delivery í™•ì¸\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langfuse import Langfuse\n",
    "\n",
    "def parse_prompty(path: Path):\n",
    "    \"\"\"Langfuse-style .prompty â†’ ChatPrompt í˜•íƒœë¡œ ë³€í™˜\"\"\"\n",
    "    content = path.read_text(encoding=\"utf-8\")\n",
    "    sections = content.strip().split('---')\n",
    "\n",
    "    if len(sections) < 3:\n",
    "        raise ValueError(\"âŒ .prompty íŒŒì¼ì€ YAML + system + user prompt í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    _ = sections[1]\n",
    "    prompt_block = sections[2]\n",
    "\n",
    "    # ê° ë¶€ë¶„ ì¶”ì¶œ\n",
    "    system_prompt = \"\"\n",
    "    user_prompt = \"\"\n",
    "    current_role = None\n",
    "    lines = prompt_block.strip().splitlines()\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip().startswith(\"system:\"):\n",
    "            current_role = \"system\"\n",
    "            continue\n",
    "        elif line.strip().startswith(\"user:\"):\n",
    "            current_role = \"user\"\n",
    "            continue\n",
    "\n",
    "        if current_role == \"system\":\n",
    "            system_prompt += line + \"\\n\"\n",
    "        elif current_role == \"user\":\n",
    "            user_prompt += line + \"\\n\"\n",
    "    \n",
    "    print(system_prompt)\n",
    "    print(user_prompt)\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
    "        {\"role\": \"user\", \"content\": user_prompt.strip()}\n",
    "    ]\n",
    "\n",
    "# Langfuse Prompt ë“±ë¡\n",
    "lf = Langfuse()\n",
    "PROMPT_PATH = Path(\"../prompts/01_order_delivery/v1_0.prompty\")\n",
    "PROMPT_NAME = \"order_delivery.v1_0\"\n",
    "version = \"1.0\"\n",
    "\n",
    "chat_prompt = parse_prompty(PROMPT_PATH)\n",
    "\n",
    "try:\n",
    "    existing = lf.get_prompt(name=PROMPT_NAME, type=\"chat\")\n",
    "except Exception as e:\n",
    "    if \"404\" in str(e):\n",
    "        existing = None\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "if existing:\n",
    "    lf.update_prompt(\n",
    "        prompt_id = existing.id,\n",
    "        prompt    = chat_prompt,\n",
    "        tags      = [\"smart_cs\"],\n",
    "        labels    = [\"stable\"],\n",
    "    )\n",
    "    print(\"ğŸ”„ Prompt updated (v1.0)\")\n",
    "else:\n",
    "    lf.create_prompt(\n",
    "        name      = PROMPT_NAME,\n",
    "        type      = \"chat\",\n",
    "        prompt    = chat_prompt,\n",
    "        tags      = [\"smart_cs\"],\n",
    "        labels    = [\"stable\"],\n",
    "    )\n",
    "    print(\"âœ… Prompt created (v1.0)\")\n",
    "\n",
    "print(\"ğŸ‘€ Langfuse UI â–¸ Prompts â–¸ order_delivery í™•ì¸\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13caf852",
   "metadata": {},
   "source": [
    "## ì‘ì—…í•œ V1.0 Prompty íŒŒì¼ ë¶ˆëŸ¬ì™€ì„œ, ì‹œë‚˜ë¦¬ì˜¤ ê²°ê³¼ ëŒë¦¬ê¸°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "325798ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "def render_prompt(messages: list, variables: dict) -> list:\n",
    "    \"\"\"Langfuse prompt template (list of dicts) â†’ rendered OpenAI messages\"\"\"\n",
    "    rendered = []\n",
    "    for message in messages:\n",
    "        role = message[\"role\"]\n",
    "        content_template = message[\"content\"]\n",
    "        content = Template(content_template).render(**variables)\n",
    "        rendered.append({\"role\": role, \"content\": content})\n",
    "    return rendered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "112a9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê²°ê³¼ ì €ì¥: ../data/01_order_delivery/answer_results/Scenario_QA_V1_gpt-4o-mini_20250615_191727.xlsx\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "â€¢ Scenario_QA.csv â†’ 10ê±´ Async ì²˜ë¦¬(gpt-4o-mini)\n",
    "â€¢ í”„ë¡¬í”„íŠ¸: order_delivery/v1_0@stable (smart_cs)\n",
    "â€¢ ê²°ê³¼: data/01_order_delivery/answer_results/Scenario_QA_V1_gpt-4o-mini_<ts>.xlsx\n",
    "\"\"\"\n",
    "import asyncio, time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import nest_asyncio, pandas as pd\n",
    "from langfuse import Langfuse\n",
    "from openai import AsyncOpenAI\n",
    "from langfuse.decorators import langfuse_context\n",
    "from langfuse.decorators import observe\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# â”€â”€â”€ ê²½ë¡œ ì„¸íŒ… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "BASE = Path(\"../data/01_order_delivery\")\n",
    "RESULT_DIR = BASE / \"answer_results\"\n",
    "RESULT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# â”€â”€â”€ Langfuse / Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "lf  = Langfuse()\n",
    "PROMPT = lf.get_prompt(\"order_delivery.v1_0\", label=\"stable\").prompt  # <-- ë ˆì´ë¸” lookup\n",
    "\n",
    "# â”€â”€â”€ CSV ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "scenario = pd.read_csv(BASE / \"Scenario_QA.csv\")\n",
    "cust     = pd.read_csv(BASE / \"Customer_Info.csv\")\n",
    "addr     = pd.read_csv(BASE / \"Delivery_Address.csv\")\n",
    "order    = pd.read_csv(BASE / \"Order_Info.csv\")\n",
    "shipping = pd.read_csv(BASE / \"Shipping_Issue_Log.csv\")\n",
    "\n",
    "df = (\n",
    "    scenario\n",
    "    .merge(cust,  on=\"customer_id\", suffixes=(\"\", \"_cust\"), how=\"left\")\n",
    "    .merge(order, on=\"customer_id\", suffixes=(\"\", \"_order\"), how=\"left\")\n",
    "    .merge(addr, on=\"customer_id\", suffixes=(\"\", \"_addr\"), how=\"left\")\n",
    "    .merge(shipping, on=\"order_id\", suffixes=(\"\", \"_shipping\"), how=\"left\")\n",
    ")\n",
    "\n",
    "# â”€â”€â”€ LLM í˜¸ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MODEL  = \"gpt-4o-mini\"\n",
    "client = AsyncOpenAI()  # OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”\n",
    "\n",
    "@observe()\n",
    "async def call_llm(row):\n",
    "    prompt_input = {\n",
    "        \"question\":          row.question,\n",
    "        \"customer_id\":       row.customer_id,\n",
    "        \"customer_name\":     row.customer_name,\n",
    "        \"order_id\":          row.order_id,\n",
    "        \"product_name\":      row.product_name,\n",
    "        \"shipping_status\":   row.shipping_status,\n",
    "        \"last_update\":       row.last_update or \"\",\n",
    "        \"shipping_company\":  row.shipping_company or \"\",\n",
    "        \"tracking_number\":   row.tracking_number or \"\",\n",
    "        \"address_line1\":     row.address_line1,\n",
    "        \"city\":              row.city,\n",
    "        \"postal_code\":       row.postal_code,\n",
    "    }\n",
    "\n",
    "    # Langfuse trace (session metadata)\n",
    "    langfuse_context.update_current_trace(\n",
    "        name       = \"order_delivery\",\n",
    "        user_id    = row.customer_id,\n",
    "        session_id = row.scenario_id,\n",
    "        tags       = [\"V1\", \"smart_cs\"],\n",
    "        metadata   = {\"model\": MODEL},\n",
    "    )\n",
    "\n",
    "    # Langfuse Prompt í…œí”Œë¦¿ ë©”ì‹œì§€ â†’ ì‹¤ì œ messages ìƒì„±\n",
    "    rendered_messages = render_prompt(PROMPT, prompt_input)\n",
    "\n",
    "    start = time.perf_counter_ns()\n",
    "\n",
    "    # ì§ì ‘ OpenAI í˜¸ì¶œ\n",
    "    response = await client.chat.completions.create(\n",
    "        model       = MODEL,\n",
    "        messages    = rendered_messages,\n",
    "        temperature = 0.3,\n",
    "        max_tokens  = 350,\n",
    "    )\n",
    "\n",
    "    latency_ms = (time.perf_counter_ns() - start) / 1e6\n",
    "\n",
    "    return response.choices[0].message.content, latency_ms, response.usage.prompt_tokens, response.usage.completion_tokens\n",
    "\n",
    "async def main():\n",
    "    tasks   = [call_llm(row) for _, row in df.iterrows()]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    out = df.copy()\n",
    "    out[[\"answer\", \"latency_ms\", \"prompt_tokens\", \"completion_tokens\"]] = pd.DataFrame(results)\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_path = RESULT_DIR / f\"Scenario_QA_V1_gpt-4o-mini_{ts}.xlsx\"\n",
    "    out.to_excel(out_path, index=False)\n",
    "    print(f\"âœ… ê²°ê³¼ ì €ì¥: {out_path}\")\n",
    "\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bf5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
