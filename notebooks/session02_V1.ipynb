{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3527062",
   "metadata": {},
   "source": [
    "# Sessionâ€¯2 â€” Prompt Engineering ì‹¤ìŠµ (V1)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ *ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§* ì‹¤ìŠµìš©ìœ¼ë¡œ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.  \n",
    "- **ë¬¸ì œ ì •ì˜ â†’ V0 â†’ V1 â†’ V2** ìˆœìœ¼ë¡œ ë‹¨ê³„ë³„ ê°œì„  ê³¼ì •ì„ ì²´í—˜í•©ë‹ˆë‹¤.  \n",
    "- ì˜¤ì§ **`gptâ€‘4oâ€‘mini`** ëª¨ë¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
    "- ì‹¤ì œ íšŒì‚¬ ë°ì´í„° ëŒ€ì‹  *ìƒ˜í”Œ* ì‹œë‚˜ë¦¬ì˜¤ 3ì¢…(`order_delivery`, `refund`, `account_login`)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
    "- ê° ë²„ì „ë³„ **ì‘ë‹µ ë‚´ìš©Â·ì§€ì—° ì‹œê°„Â·ë¹„ìš©**ì„ ë¹„êµí•´ ë³´ì„¸ìš”.\n",
    "\n",
    "> ì‹¤ìŠµ ê²°ê³¼ëŠ” ê°œì¸ë³„ë¡œ V0.xÂ ~Â V0.3 ë“±ì˜ ë²„ì „ì„ ì¶”ê°€í•˜ë©° ììœ ë¡­ê²Œ ë°œì „ì‹œí‚¤ë©´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5142eb0",
   "metadata": {},
   "source": [
    "## íŒ¨í‚¤ì§€ ì„¤ì¹˜ (Colab ë˜ëŠ” ë¡œì»¬)\n",
    "\n",
    "í•„ìš”í•œ ê²½ìš° ì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca2fc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jinja2==3.1.5 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (3.1.5)\n",
      "Requirement already satisfied: numpy==2.2.3 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: openai==1.65.5 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 3)) (1.65.5)\n",
      "Collecting langfuse==2.60.5 (from -r ../requirements.txt (line 4))\n",
      "  Obtaining dependency information for langfuse==2.60.5 from https://files.pythonhosted.org/packages/e9/04/8d69112a6b24431bfdb257a2a394f0ab036e5be5dcf4cb3b15db43b367f6/langfuse-2.60.5-py3-none-any.whl.metadata\n",
      "  Downloading langfuse-2.60.5-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: openpyxl==3.1.5 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 5)) (3.1.5)\n",
      "Requirement already satisfied: pandas==2.2.3 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 6)) (2.2.3)\n",
      "Requirement already satisfied: notion-client==2.3.0 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 7)) (2.3.0)\n",
      "Requirement already satisfied: xlsxwriter==3.2.0 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: aiohttp==3.9.1 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 9)) (3.9.1)\n",
      "Requirement already satisfied: nest_asyncio==1.5.7 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 10)) (1.5.7)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2==3.1.5->-r ../requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (2.11.5)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/homebrew/lib/python3.10/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (2.2.1)\n",
      "Requirement already satisfied: idna<4.0,>=3.7 in /opt/homebrew/lib/python3.10/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: packaging<25.0,>=23.2 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (24.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/lib/python3.10/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (2.32.4)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /opt/homebrew/lib/python3.10/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (1.17.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/homebrew/lib/python3.10/site-packages (from openpyxl==3.1.5->-r ../requirements.txt (line 5)) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from pandas==2.2.3->-r ../requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas==2.2.3->-r ../requirements.txt (line 6)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.10/site-packages (from pandas==2.2.3->-r ../requirements.txt (line 6)) (2025.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (25.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (6.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (1.20.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (1.7.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (4.0.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from anyio<5,>=3.5.0->openai==1.65.5->-r ../requirements.txt (line 3)) (1.2.1)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.65.5->-r ../requirements.txt (line 3)) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.65.5->-r ../requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.65.5->-r ../requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.65.5->-r ../requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.65.5->-r ../requirements.txt (line 3)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.65.5->-r ../requirements.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r ../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests<3,>=2->langfuse==2.60.5->-r ../requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests<3,>=2->langfuse==2.60.5->-r ../requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /opt/homebrew/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp==3.9.1->-r ../requirements.txt (line 9)) (0.3.2)\n",
      "Downloading langfuse-2.60.5-py3-none-any.whl (275 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m275.4/275.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langfuse\n",
      "  Attempting uninstall: langfuse\n",
      "    Found existing installation: langfuse 2.59.7\n",
      "    Uninstalling langfuse-2.59.7:\n",
      "      Successfully uninstalled langfuse-2.59.7\n",
      "Successfully installed langfuse-2.60.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b33eb",
   "metadata": {},
   "source": [
    "## í™˜ê²½ ì„¤ì • ë° ê³µí†µ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2c7a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, asyncio, time\n",
    "import nest_asyncio, pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langfuse import Langfuse\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "USE_STUB = OPENAI_API_KEY is None\n",
    "langfuse = Langfuse()\n",
    "\n",
    "if USE_STUB:\n",
    "    print(\"ğŸ”§  Stub ëª¨ë“œ: OPENAI_API_KEY ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‹¤ì œ API í˜¸ì¶œ ëŒ€ì‹  ë”ë¯¸ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    from langfuse.openai import AsyncOpenAI\n",
    "    client = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ê°€ê²©(USD / token)\n",
    "PRICING = {\"input\": 0.15/1_000_000, \"output\": 0.60/1_000_000}\n",
    "\n",
    "async def call_openai(system_prompt: str, user_prompt: str, model: str = \"gpt-4o-mini\"):\n",
    "    start = time.perf_counter_ns()\n",
    "    if USE_STUB:\n",
    "        await asyncio.sleep(0.05)  # ì§€ì—° ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜\n",
    "        answer = f\"[STUB] '{user_prompt[:25]}...' ì— ëŒ€í•œ ì˜ˆì‹œ ì‘ë‹µ\"\n",
    "        prompt_tokens = len(system_prompt.split()) + len(user_prompt.split())\n",
    "        completion_tokens = 120\n",
    "    else:\n",
    "        resp = await client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "        )\n",
    "        answer = resp.choices[0].message.content.strip()\n",
    "        usage = resp.usage\n",
    "        prompt_tokens = usage.prompt_tokens\n",
    "        completion_tokens = usage.completion_tokens\n",
    "    latency_ms = (time.perf_counter_ns() - start) / 1_000_000\n",
    "    cost = prompt_tokens * PRICING[\"input\"] + completion_tokens * PRICING[\"output\"]\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"latency_ms\": latency_ms,\n",
    "        \"prompt_tokens\": prompt_tokens,\n",
    "        \"completion_tokens\": completion_tokens,\n",
    "        \"usd_cost\": cost,\n",
    "    }\n",
    "\n",
    "async def run_version(df: pd.DataFrame, version_name: str, build_system_prompt):\n",
    "    tasks = []\n",
    "    for _, row in df.iterrows():\n",
    "        tasks.append(call_openai(build_system_prompt(row), row['question']))\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    # ê²°ê³¼ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³‘í•©\n",
    "    for idx, res in enumerate(results):\n",
    "        for key, val in res.items():\n",
    "            df.loc[idx, f\"{version_name}_{key}\"] = val\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc54e59",
   "metadata": {},
   "source": [
    "## ì˜ˆì‹œ ì‹œë‚˜ë¦¬ì˜¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b45cc54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>ì£¼ë¬¸í•œ ìƒí’ˆì´ ë°°ì†¡ ì˜ˆì •ì¼ì„ ì§€ë‚¬ëŠ”ë° ì•„ì§ ë„ì°©í•˜ì§€ ì•Šì•˜ì–´ìš”. ì–´ë–»ê²Œ í™•ì¸í•˜ë‚˜ìš”?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>ë°˜í’ˆ ì‹ ì²­ì„ í–ˆëŠ”ë° í™˜ë¶ˆ ì²˜ë¦¬ê°€ ì–¸ì œ ì™„ë£Œë˜ë‚˜ìš”?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>ë¡œê·¸ì¸ ì‹œë„ ì‹œ 2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆë‚˜ìš”?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario                                       question\n",
       "0  order_delivery  ì£¼ë¬¸í•œ ìƒí’ˆì´ ë°°ì†¡ ì˜ˆì •ì¼ì„ ì§€ë‚¬ëŠ”ë° ì•„ì§ ë„ì°©í•˜ì§€ ì•Šì•˜ì–´ìš”. ì–´ë–»ê²Œ í™•ì¸í•˜ë‚˜ìš”?\n",
       "1          refund                    ë°˜í’ˆ ì‹ ì²­ì„ í–ˆëŠ”ë° í™˜ë¶ˆ ì²˜ë¦¬ê°€ ì–¸ì œ ì™„ë£Œë˜ë‚˜ìš”?\n",
       "2   account_login      ë¡œê·¸ì¸ ì‹œë„ ì‹œ 2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆë‚˜ìš”?"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios = [\n",
    "    {\"scenario\": \"order_delivery\", \"question\": \"ì£¼ë¬¸í•œ ìƒí’ˆì´ ë°°ì†¡ ì˜ˆì •ì¼ì„ ì§€ë‚¬ëŠ”ë° ì•„ì§ ë„ì°©í•˜ì§€ ì•Šì•˜ì–´ìš”. ì–´ë–»ê²Œ í™•ì¸í•˜ë‚˜ìš”?\"},\n",
    "    {\"scenario\": \"refund\", \"question\": \"ë°˜í’ˆ ì‹ ì²­ì„ í–ˆëŠ”ë° í™˜ë¶ˆ ì²˜ë¦¬ê°€ ì–¸ì œ ì™„ë£Œë˜ë‚˜ìš”?\"},\n",
    "    {\"scenario\": \"account_login\", \"question\": \"ë¡œê·¸ì¸ ì‹œë„ ì‹œ 2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆë‚˜ìš”?\"},\n",
    "]\n",
    "df = pd.DataFrame(scenarios)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1589f884",
   "metadata": {},
   "source": [
    "## V0.0 â€” Zeroâ€‘Shot (System Prompt ì—†ì´ ë°”ë¡œ ì§ˆë¬¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6ce598d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>V0_0_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>ì£¼ë¬¸í•œ ìƒí’ˆì´ ë°°ì†¡ ì˜ˆì •ì¼ì„ ì§€ë‚˜ë„ ë„ì°©í•˜ì§€ ì•Šì€ ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ í™•ì¸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>ë°˜í’ˆ ì‹ ì²­ í›„ í™˜ë¶ˆ ì²˜ë¦¬ ì™„ë£Œê¹Œì§€ ì†Œìš”ë˜ëŠ” ì‹œê°„ì€ ì£¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ìš”ì†Œì— ë”°ë¼ ë‹¬...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario                                        V0_0_answer\n",
       "0  order_delivery  ì£¼ë¬¸í•œ ìƒí’ˆì´ ë°°ì†¡ ì˜ˆì •ì¼ì„ ì§€ë‚˜ë„ ë„ì°©í•˜ì§€ ì•Šì€ ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ í™•ì¸...\n",
       "1          refund  ë°˜í’ˆ ì‹ ì²­ í›„ í™˜ë¶ˆ ì²˜ë¦¬ ì™„ë£Œê¹Œì§€ ì†Œìš”ë˜ëŠ” ì‹œê°„ì€ ì£¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ìš”ì†Œì— ë”°ë¼ ë‹¬...\n",
       "2   account_login  2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sys_prompt_v0_0(row):\n",
    "    return \"\"\n",
    "\n",
    "await run_version(df, \"V0_0\", sys_prompt_v0_0)\n",
    "df[['scenario', 'V0_0_answer']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80fcc52",
   "metadata": {},
   "source": [
    "## V0.1 â€” Persona + Tone + Clear Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eb01104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>V0_1_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”, ê³ ê°ë‹˜. ë°°ì†¡ ì˜ˆì •ì¼ì´ ì§€ë‚˜ë„ ìƒí’ˆì´ ë„ì°©í•˜ì§€ ì•Šì€ ì  ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>ê³ ê°ë‹˜, ë°˜í’ˆ ì‹ ì²­ í›„ í™˜ë¶ˆ ì²˜ë¦¬ì—ëŠ” ë³´í†µ 3-7ì¼ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤. ë°˜í’ˆ ìƒí’ˆì´ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”. 2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ë¡œ ì¸í•´ ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ë¨¼ì €, ì¸ì¦ ì½”ë“œê°€ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario                                        V0_1_answer\n",
       "0  order_delivery  ì•ˆë…•í•˜ì„¸ìš”, ê³ ê°ë‹˜. ë°°ì†¡ ì˜ˆì •ì¼ì´ ì§€ë‚˜ë„ ìƒí’ˆì´ ë„ì°©í•˜ì§€ ì•Šì€ ì  ì‚¬ê³¼ë“œë¦½ë‹ˆë‹¤. ...\n",
       "1          refund  ê³ ê°ë‹˜, ë°˜í’ˆ ì‹ ì²­ í›„ í™˜ë¶ˆ ì²˜ë¦¬ì—ëŠ” ë³´í†µ 3-7ì¼ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤. ë°˜í’ˆ ìƒí’ˆì´ ...\n",
       "2   account_login  ì•ˆë…•í•˜ì„¸ìš”. 2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ë¡œ ì¸í•´ ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ë¨¼ì €, ì¸ì¦ ì½”ë“œê°€ ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sys_prompt_v0_1(row):\n",
    "    return (\n",
    "        \"You are a calm and professional Korean CS chatbot for an eâ€‘commerce platform. \"\n",
    "        \"Answer politely in Korean, maximum 5 sentences.\"\n",
    "    )\n",
    "\n",
    "await run_version(df, \"V0_1\", sys_prompt_v0_1)\n",
    "df[['scenario','V0_1_answer']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306705c",
   "metadata": {},
   "source": [
    "## V0.2 â€” Fewâ€‘Shot + Chainâ€‘ofâ€‘Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e385730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>V0_2_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ì£¼ë¬¸í•˜ì‹  ìƒí’ˆì˜ ìš´ì†¡ì¥ ë²ˆí˜¸ë¥¼ í™•ì¸í•´ ì£¼ì‹œë©´ ë°°ì†¡ ìƒíƒœë¥¼ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>ë°˜í’ˆ ì‹ ì²­ í›„ í™˜ë¶ˆ ì²˜ë¦¬ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 3~5ì¼ ì†Œìš”ë©ë‹ˆë‹¤. ë°˜í’ˆ ìƒí’ˆì´ ë„ì°©í•˜ê³  ê²€...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ëŠ” ì£¼ë¡œ ì…ë ¥í•œ ì „í™”ë²ˆí˜¸ì™€ ì¸ì¦ ë°©ë²• ì„¤ì •ì˜ ë¶ˆì¼ì¹˜ í˜¹ì€ ì¼ì‹œì ì¸ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario                                        V0_2_answer\n",
       "0  order_delivery  ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ì£¼ë¬¸í•˜ì‹  ìƒí’ˆì˜ ìš´ì†¡ì¥ ë²ˆí˜¸ë¥¼ í™•ì¸í•´ ì£¼ì‹œë©´ ë°°ì†¡ ìƒíƒœë¥¼ ...\n",
       "1          refund  ë°˜í’ˆ ì‹ ì²­ í›„ í™˜ë¶ˆ ì²˜ë¦¬ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 3~5ì¼ ì†Œìš”ë©ë‹ˆë‹¤. ë°˜í’ˆ ìƒí’ˆì´ ë„ì°©í•˜ê³  ê²€...\n",
       "2   account_login  2ë‹¨ê³„ ì¸ì¦ ì˜¤ë¥˜ëŠ” ì£¼ë¡œ ì…ë ¥í•œ ì „í™”ë²ˆí˜¸ì™€ ì¸ì¦ ë°©ë²• ì„¤ì •ì˜ ë¶ˆì¼ì¹˜ í˜¹ì€ ì¼ì‹œì ì¸ ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_examples = \"\"\"\n",
    "<example>\n",
    "[ê³ ê°] ì£¼ë¬¸í•œ ìƒí’ˆì´ ì•„ì§ ë„ì°©í•˜ì§€ ì•Šì•˜ì–´ìš”!\n",
    "[ì±—ë´‡] ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ìš´ì†¡ì¥ ë²ˆí˜¸ 123â€‘4567ì„ ì¡°íšŒí•´ ë³´ë‹ˆ í˜„ì¬ ë¬¼ë¥˜ì„¼í„°ì— ìˆìŠµë‹ˆë‹¤. 1~2ì¼ ë‚´ ë„ì°© ì˜ˆì •ì´ë©°, ì§€ì—° ì‹œ ë°”ë¡œ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
    "</example>\n",
    "\"\"\"\n",
    "\n",
    "def sys_prompt_v0_2(row):\n",
    "    return (\n",
    "        f\"{few_shot_examples}\\n\\n\"\n",
    "        \"You are a CS assistant. Think stepâ€‘byâ€‘step to figure out the cause internally, \"\n",
    "        \"but provide only the final concise answer in Korean (max 5 lines).\"\n",
    "    )\n",
    "\n",
    "await run_version(df, \"V0_2\", sys_prompt_v0_2)\n",
    "df[['scenario','V0_2_answer']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da1030",
   "metadata": {},
   "source": [
    "## ë²„ì „ë³„ ë¹„êµ (Latency & Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce880de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>V0_0_latency_ms</th>\n",
       "      <th>V0_0_usd_cost</th>\n",
       "      <th>V0_1_latency_ms</th>\n",
       "      <th>V0_1_usd_cost</th>\n",
       "      <th>V0_2_latency_ms</th>\n",
       "      <th>V0_2_usd_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>5201.338833</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>1545.340375</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>1634.396875</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>8404.851375</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>1648.630500</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1440.019500</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>5667.732541</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>2128.210834</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>3735.301250</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario  V0_0_latency_ms  V0_0_usd_cost  V0_1_latency_ms  \\\n",
       "0  order_delivery      5201.338833       0.000153      1545.340375   \n",
       "1          refund      8404.851375       0.000107      1648.630500   \n",
       "2   account_login      5667.732541       0.000199      2128.210834   \n",
       "\n",
       "   V0_1_usd_cost  V0_2_latency_ms  V0_2_usd_cost  \n",
       "0       0.000049      1634.396875       0.000072  \n",
       "1       0.000058      1440.019500       0.000050  \n",
       "2       0.000068      3735.301250       0.000066  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_cols = ['scenario']\n",
    "for v in ['V0_0','V0_1','V0_2']:\n",
    "    compare_cols += [f\"{v}_latency_ms\", f\"{v}_usd_cost\"]\n",
    "df[compare_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a01b92",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœï¸ ê°œì¸ ì‹¤ìŠµ ì˜ì—­\n",
    "\n",
    "ì•„ë˜ ë¹ˆ ì…€ì„ ë³µì‚¬í•˜ì—¬ **V0.1 ~ V0.3** ë“± ìì‹ ë§Œì˜ ë³€í˜•ì„ ì‹œë„í•´ ë³´ì„¸ìš”.  \n",
    "- ìƒˆë¡œìš´ System Promptë¥¼ ì„¤ê³„í•˜ê±°ë‚˜  \n",
    "- Fewâ€‘Shot ì˜ˆì‹œ ê°œìˆ˜ë¥¼ ëŠ˜ë¦¬ê±°ë‚˜  \n",
    "- ELI5, JSON í¬ë§· ë“± ì¶”ê°€ ìš”êµ¬ì‚¬í•­ì„ ë„£ì–´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ì—¬ê¸°ì— ê°œì¸ ì‹¤ìŠµ ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba01ef8",
   "metadata": {},
   "source": [
    "# ë ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84acbd8",
   "metadata": {},
   "source": [
    "## ì‘ì—…í•œ V1.0 Prompt Langfuseì— ë“±ë¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a75a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ë‹¹ì‹ ì€ 30ëŒ€ ì¤‘ë°˜ì˜ ìˆ™ë ¨ëœ ì „ììƒê±°ë˜ ë°°ì†¡ CS ë‹´ë‹¹ìì…ë‹ˆë‹¤.  \n",
      "  ë§íˆ¬ëŠ” ì°¨ë¶„í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”.  \n",
      "  \n",
      "  ### ë‚´ë¶€ ì‚¬ê³ (Chain-of-Thought) ê°€ì´ë“œ â€” ê³ ê°ì—ê²ŒëŠ” ë³´ì´ì§€ ì•Šë„ë¡!  \n",
      "  1. ì§ˆë¬¸ì—ì„œ ìš”êµ¬í•˜ëŠ” ì •ë³´ê°€ ì£¼ì†Œ ë³€ê²½/ë°°ì†¡ ì§€ì—°/ìš´ì†¡ì¥ ë“± ì–´ëŠ ìœ í˜•ì¸ì§€ ë¶„ë¥˜  \n",
      "  2. CSVë¡œ ì „ë‹¬ëœ ì£¼ë¬¸Â·ì£¼ì†ŒÂ·ë°°ì†¡ ìƒíƒœë¥¼ ë‹¨ê³„ë³„ë¡œ ì ê²€  \n",
      "  3. í•´ê²° ì ˆì°¨Â·ì˜ˆìƒ ì¼ì •Â·ì¬ë°œ ì•Œë¦¼ ë“±ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì •ë¦¬\n",
      "  \n",
      "  ### ìµœì¢… ì‘ë‹µ í˜•ì‹ â€” í•œêµ­ì–´ 120ë‹¨ì–´ ì´ë‚´  \n",
      "  â€¢ ê³ ê°ëª… + ì£¼ë¬¸Â·ìƒí’ˆÂ·ìƒíƒœ ìš”ì•½  \n",
      "  â€¢ ë‹¤ìŒ ì§„í–‰ ë‹¨ê³„ or ì¡°ì¹˜(ìˆ«ì ëª©ë¡ ì‚¬ìš©)  \n",
      "  â€¢ ë§ˆë¬´ë¦¬ ë¬¸êµ¬: â€œì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”.â€\n",
      "\n",
      "  ### ì§ˆë¬¸\n",
      "  {{question}}\n",
      "  \n",
      "  ### ê³ ê°Â·ì£¼ë¬¸ ì»¨í…ìŠ¤íŠ¸\n",
      "  ID: {{customer_id}}  ì´ë¦„: {{customer_name}}\n",
      "  ì£¼ë¬¸ë²ˆí˜¸: {{order_id}}  ìƒí’ˆ: {{product_name}}\n",
      "  ë°°ì†¡ìƒíƒœ: {{shipping_status}}  (ìµœê·¼ ì—…ë°ì´íŠ¸: {{last_update}})\n",
      "  íƒë°°ì‚¬: {{shipping_company}}  ì†¡ì¥: {{tracking_number}}\n",
      "  ê¸°ë³¸ì£¼ì†Œ: {{address_line1}}, {{city}} {{postal_code}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while fetching prompt 'order_delivery/v1_0-label:production': status_code: 404, body: <!DOCTYPE html><html lang=\"en\"><head><meta charSet=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width\"/><meta name=\"next-head-count\" content=\"2\"/><link rel=\"preload\" href=\"/_next/static/css/08b3e129faadb9d6.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/08b3e129faadb9d6.css\" data-n-g=\"\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-42372ed130431b0a.js\"></script><script src=\"/_next/static/chunks/webpack-3493017210f8f3cb.js\" defer=\"\"></script><script src=\"/_next/static/chunks/framework-9e13880ebb429a2d.js\" defer=\"\"></script><script src=\"/_next/static/chunks/main-9c9c77a3987594f4.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_app-39a9ec525d0fcf02.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_error-d748218a48df77d2.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_buildManifest.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_ssgManifest.js\" defer=\"\"></script></head><body><div id=\"__next\"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class=\"flex min-h-full flex-1 flex-col justify-center py-12 sm:px-6 lg:px-8\" data-sentry-component=\"Spinner\" data-sentry-source-file=\"spinner.tsx\"><div class=\"sm:mx-auto sm:w-full sm:max-w-md\"><img src=\"/icon.svg\" width=\"42\" height=\"42\" alt=\"Langfuse Icon\" class=\"mx-auto motion-safe:animate-spin\" data-sentry-component=\"LangfuseIcon\" data-sentry-source-file=\"LangfuseLogo.tsx\"/><h2 class=\"mt-5 text-center text-2xl font-bold leading-9 tracking-tight text-primary\">Loading<!-- --> ...</h2></div></div><script src=\"https://uptime.betterstack.com/widgets/announcement.js\" data-id=\"189328\" async=\"\" type=\"text/javascript\" data-sentry-component=\"BetterStackUptimeStatusMessage\" data-sentry-source-file=\"_app.tsx\"></script></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{\"statusCode\":404}},\"page\":\"/_error\",\"query\":{},\"buildId\":\"ths-eUPeeEuP005_wv51H\",\"nextExport\":true,\"isFallback\":false,\"gip\":true,\"locale\":\"en\",\"locales\":[\"en\"],\"defaultLocale\":\"en\",\"scriptLoader\":[]}</script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML=\"window.__CF$cv$params={r:'95014c52ef02fcd8',t:'MTc0OTk4MjQ0MS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);\";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body></html>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prompt created (v1.0)\n",
      "ğŸ‘€ Langfuse UI â–¸ Prompts â–¸ order_delivery í™•ì¸\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langfuse import Langfuse\n",
    "\n",
    "def parse_prompty(path: Path):\n",
    "    \"\"\"Langfuse-style .prompty â†’ ChatPrompt í˜•íƒœë¡œ ë³€í™˜\"\"\"\n",
    "    content = path.read_text(encoding=\"utf-8\")\n",
    "    sections = content.strip().split('---')\n",
    "\n",
    "    if len(sections) < 3:\n",
    "        raise ValueError(\"âŒ .prompty íŒŒì¼ì€ YAML + system + user prompt í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    _ = sections[1]\n",
    "    prompt_block = sections[2]\n",
    "\n",
    "    # ê° ë¶€ë¶„ ì¶”ì¶œ\n",
    "    system_prompt = \"\"\n",
    "    user_prompt = \"\"\n",
    "    current_role = None\n",
    "    lines = prompt_block.strip().splitlines()\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip().startswith(\"system:\"):\n",
    "            current_role = \"system\"\n",
    "            continue\n",
    "        elif line.strip().startswith(\"user:\"):\n",
    "            current_role = \"user\"\n",
    "            continue\n",
    "\n",
    "        if current_role == \"system\":\n",
    "            system_prompt += line + \"\\n\"\n",
    "        elif current_role == \"user\":\n",
    "            user_prompt += line + \"\\n\"\n",
    "    \n",
    "    print(system_prompt)\n",
    "    print(user_prompt)\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
    "        {\"role\": \"user\", \"content\": user_prompt.strip()}\n",
    "    ]\n",
    "\n",
    "# Langfuse Prompt ë“±ë¡\n",
    "lf = Langfuse()\n",
    "PROMPT_PATH = Path(\"../prompts/01_order_delivery/v1_0.prompty\")\n",
    "PROMPT_NAME = \"order_delivery/v1_0\"\n",
    "version = \"1.0\"\n",
    "\n",
    "chat_prompt = parse_prompty(PROMPT_PATH)\n",
    "\n",
    "try:\n",
    "    existing = lf.get_prompt(name=PROMPT_NAME, type=\"chat\")\n",
    "except Exception as e:\n",
    "    if \"404\" in str(e):\n",
    "        existing = None\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "if existing:\n",
    "    lf.update_prompt(\n",
    "        prompt_id = existing.id,\n",
    "        prompt    = chat_prompt,\n",
    "        tags      = [\"smart_cs\"],\n",
    "        labels    = [\"stable\"],\n",
    "    )\n",
    "    print(\"ğŸ”„ Prompt updated (v1.0)\")\n",
    "else:\n",
    "    lf.create_prompt(\n",
    "        name      = PROMPT_NAME,\n",
    "        type      = \"chat\",\n",
    "        prompt    = chat_prompt,\n",
    "        tags      = [\"smart_cs\"],\n",
    "        labels    = [\"stable\"],\n",
    "    )\n",
    "    print(\"âœ… Prompt created (v1.0)\")\n",
    "\n",
    "print(\"ğŸ‘€ Langfuse UI â–¸ Prompts â–¸ order_delivery í™•ì¸\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13caf852",
   "metadata": {},
   "source": [
    "## ì‘ì—…í•œ V1.0 Prompty íŒŒì¼ ë¶ˆëŸ¬ì™€ì„œ, ì‹œë‚˜ë¦¬ì˜¤ ê²°ê³¼ ëŒë¦¬ê¸°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "325798ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "def render_prompt(messages: list, variables: dict) -> list:\n",
    "    \"\"\"Langfuse prompt template (list of dicts) â†’ rendered OpenAI messages\"\"\"\n",
    "    rendered = []\n",
    "    for message in messages:\n",
    "        role = message[\"role\"]\n",
    "        content_template = message[\"content\"]\n",
    "        content = Template(content_template).render(**variables)\n",
    "        rendered.append({\"role\": role, \"content\": content})\n",
    "    return rendered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while fetching prompt 'order_delivery/v1_0-label:stable': status_code: 404, body: <!DOCTYPE html><html lang=\"en\"><head><meta charSet=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width\"/><meta name=\"next-head-count\" content=\"2\"/><link rel=\"preload\" href=\"/_next/static/css/08b3e129faadb9d6.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/08b3e129faadb9d6.css\" data-n-g=\"\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-42372ed130431b0a.js\"></script><script src=\"/_next/static/chunks/webpack-3493017210f8f3cb.js\" defer=\"\"></script><script src=\"/_next/static/chunks/framework-9e13880ebb429a2d.js\" defer=\"\"></script><script src=\"/_next/static/chunks/main-9c9c77a3987594f4.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_app-39a9ec525d0fcf02.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_error-d748218a48df77d2.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_buildManifest.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_ssgManifest.js\" defer=\"\"></script></head><body><div id=\"__next\"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class=\"flex min-h-full flex-1 flex-col justify-center py-12 sm:px-6 lg:px-8\" data-sentry-component=\"Spinner\" data-sentry-source-file=\"spinner.tsx\"><div class=\"sm:mx-auto sm:w-full sm:max-w-md\"><img src=\"/icon.svg\" width=\"42\" height=\"42\" alt=\"Langfuse Icon\" class=\"mx-auto motion-safe:animate-spin\" data-sentry-component=\"LangfuseIcon\" data-sentry-source-file=\"LangfuseLogo.tsx\"/><h2 class=\"mt-5 text-center text-2xl font-bold leading-9 tracking-tight text-primary\">Loading<!-- --> ...</h2></div></div><script src=\"https://uptime.betterstack.com/widgets/announcement.js\" data-id=\"189328\" async=\"\" type=\"text/javascript\" data-sentry-component=\"BetterStackUptimeStatusMessage\" data-sentry-source-file=\"_app.tsx\"></script></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{\"statusCode\":404}},\"page\":\"/_error\",\"query\":{},\"buildId\":\"ths-eUPeeEuP005_wv51H\",\"nextExport\":true,\"isFallback\":false,\"gip\":true,\"locale\":\"en\",\"locales\":[\"en\"],\"defaultLocale\":\"en\",\"scriptLoader\":[]}</script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML=\"window.__CF$cv$params={r:'95014cdb59befcda',t:'MTc0OTk4MjQ2My4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);\";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body></html>\n"
     ]
    },
    {
     "ename": "ApiError",
     "evalue": "status_code: 404, body: <!DOCTYPE html><html lang=\"en\"><head><meta charSet=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width\"/><meta name=\"next-head-count\" content=\"2\"/><link rel=\"preload\" href=\"/_next/static/css/08b3e129faadb9d6.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/08b3e129faadb9d6.css\" data-n-g=\"\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-42372ed130431b0a.js\"></script><script src=\"/_next/static/chunks/webpack-3493017210f8f3cb.js\" defer=\"\"></script><script src=\"/_next/static/chunks/framework-9e13880ebb429a2d.js\" defer=\"\"></script><script src=\"/_next/static/chunks/main-9c9c77a3987594f4.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_app-39a9ec525d0fcf02.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_error-d748218a48df77d2.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_buildManifest.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_ssgManifest.js\" defer=\"\"></script></head><body><div id=\"__next\"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class=\"flex min-h-full flex-1 flex-col justify-center py-12 sm:px-6 lg:px-8\" data-sentry-component=\"Spinner\" data-sentry-source-file=\"spinner.tsx\"><div class=\"sm:mx-auto sm:w-full sm:max-w-md\"><img src=\"/icon.svg\" width=\"42\" height=\"42\" alt=\"Langfuse Icon\" class=\"mx-auto motion-safe:animate-spin\" data-sentry-component=\"LangfuseIcon\" data-sentry-source-file=\"LangfuseLogo.tsx\"/><h2 class=\"mt-5 text-center text-2xl font-bold leading-9 tracking-tight text-primary\">Loading<!-- --> ...</h2></div></div><script src=\"https://uptime.betterstack.com/widgets/announcement.js\" data-id=\"189328\" async=\"\" type=\"text/javascript\" data-sentry-component=\"BetterStackUptimeStatusMessage\" data-sentry-source-file=\"_app.tsx\"></script></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{\"statusCode\":404}},\"page\":\"/_error\",\"query\":{},\"buildId\":\"ths-eUPeeEuP005_wv51H\",\"nextExport\":true,\"isFallback\":false,\"gip\":true,\"locale\":\"en\",\"locales\":[\"en\"],\"defaultLocale\":\"en\",\"scriptLoader\":[]}</script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML=\"window.__CF$cv$params={r:'95014cdb59befcda',t:'MTc0OTk4MjQ2My4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);\";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body></html>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/api/resources/prompts/client.py:100\u001b[0m, in \u001b[0;36mPromptsClient.get\u001b[0;34m(self, prompt_name, version, label, request_options)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundError(\n\u001b[0;32m--> 100\u001b[0m         pydantic_v1\u001b[38;5;241m.\u001b[39mparse_obj_as(typing\u001b[38;5;241m.\u001b[39mAny, \u001b[43m_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    101\u001b[0m     )  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    102\u001b[0m _response_json \u001b[38;5;241m=\u001b[39m _response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/httpx/_models.py:832\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjson\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjsonlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mApiError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# â”€â”€â”€ Langfuse / Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39;00m\n\u001b[1;32m     23\u001b[0m lf  \u001b[38;5;241m=\u001b[39m Langfuse()\n\u001b[0;32m---> 24\u001b[0m PROMPT \u001b[38;5;241m=\u001b[39m \u001b[43mlf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morder_delivery/v1_0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mprompt  \u001b[38;5;66;03m# <-- ë ˆì´ë¸” lookup\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# â”€â”€â”€ CSV ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39;00m\n\u001b[1;32m     27\u001b[0m scenario \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(BASE \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScenario_QA.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/client.py:1199\u001b[0m, in \u001b[0;36mLangfuse.get_prompt\u001b[0;34m(self, name, version, label, type, cache_ttl_seconds, fallback, max_retries, fetch_timeout_seconds)\u001b[0m\n\u001b[1;32m   1193\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1194\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptClient(\n\u001b[1;32m   1195\u001b[0m                     prompt\u001b[38;5;241m=\u001b[39mPrompt_Chat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfallback_client_args),\n\u001b[1;32m   1196\u001b[0m                     is_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1197\u001b[0m                 )\n\u001b[0;32m-> 1199\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached_prompt\u001b[38;5;241m.\u001b[39mis_expired():\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStale prompt \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m found in cache.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/client.py:1163\u001b[0m, in \u001b[0;36mLangfuse.get_prompt\u001b[0;34m(self, name, version, label, type, cache_ttl_seconds, fallback, max_retries, fetch_timeout_seconds)\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in cache or caching disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1161\u001b[0m )\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_prompt_and_update_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mttl_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_ttl_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounded_max_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfetch_timeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fallback:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/client.py:1275\u001b[0m, in \u001b[0;36mLangfuse._fetch_prompt_and_update_cache\u001b[0;34m(self, name, version, label, ttl_seconds, max_retries, fetch_timeout_seconds)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while fetching prompt \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/client.py:1262\u001b[0m, in \u001b[0;36mLangfuse._fetch_prompt_and_update_cache\u001b[0;34m(self, name, version, label, ttl_seconds, max_retries, fetch_timeout_seconds)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;129m@backoff\u001b[39m\u001b[38;5;241m.\u001b[39mon_exception(\n\u001b[1;32m   1248\u001b[0m     backoff\u001b[38;5;241m.\u001b[39mconstant, \u001b[38;5;167;01mException\u001b[39;00m, max_tries\u001b[38;5;241m=\u001b[39mmax_retries, logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m )\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_prompts\u001b[39m():\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mprompts\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url_encode(name),\n\u001b[1;32m   1253\u001b[0m         version\u001b[38;5;241m=\u001b[39mversion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1260\u001b[0m     )\n\u001b[0;32m-> 1262\u001b[0m prompt_response \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_prompts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompt_response\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1265\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m ChatPromptClient(prompt_response)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/backoff/_sync.py:105\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m details \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: target,\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melapsed\u001b[39m\u001b[38;5;124m\"\u001b[39m: elapsed,\n\u001b[1;32m    102\u001b[0m }\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    107\u001b[0m     max_tries_exceeded \u001b[38;5;241m=\u001b[39m (tries \u001b[38;5;241m==\u001b[39m max_tries_value)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/client.py:1251\u001b[0m, in \u001b[0;36mLangfuse._fetch_prompt_and_update_cache.<locals>.fetch_prompts\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;129m@backoff\u001b[39m\u001b[38;5;241m.\u001b[39mon_exception(\n\u001b[1;32m   1248\u001b[0m     backoff\u001b[38;5;241m.\u001b[39mconstant, \u001b[38;5;167;01mException\u001b[39;00m, max_tries\u001b[38;5;241m=\u001b[39mmax_retries, logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m )\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_prompts\u001b[39m():\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_url_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeout_in_seconds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfetch_timeout_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1259\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/api/resources/prompts/client.py:104\u001b[0m, in \u001b[0;36mPromptsClient.get\u001b[0;34m(self, prompt_name, version, label, request_options)\u001b[0m\n\u001b[1;32m    102\u001b[0m     _response_json \u001b[38;5;241m=\u001b[39m _response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response_json)\n",
      "\u001b[0;31mApiError\u001b[0m: status_code: 404, body: <!DOCTYPE html><html lang=\"en\"><head><meta charSet=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width\"/><meta name=\"next-head-count\" content=\"2\"/><link rel=\"preload\" href=\"/_next/static/css/08b3e129faadb9d6.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/08b3e129faadb9d6.css\" data-n-g=\"\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-42372ed130431b0a.js\"></script><script src=\"/_next/static/chunks/webpack-3493017210f8f3cb.js\" defer=\"\"></script><script src=\"/_next/static/chunks/framework-9e13880ebb429a2d.js\" defer=\"\"></script><script src=\"/_next/static/chunks/main-9c9c77a3987594f4.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_app-39a9ec525d0fcf02.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_error-d748218a48df77d2.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_buildManifest.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_ssgManifest.js\" defer=\"\"></script></head><body><div id=\"__next\"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class=\"flex min-h-full flex-1 flex-col justify-center py-12 sm:px-6 lg:px-8\" data-sentry-component=\"Spinner\" data-sentry-source-file=\"spinner.tsx\"><div class=\"sm:mx-auto sm:w-full sm:max-w-md\"><img src=\"/icon.svg\" width=\"42\" height=\"42\" alt=\"Langfuse Icon\" class=\"mx-auto motion-safe:animate-spin\" data-sentry-component=\"LangfuseIcon\" data-sentry-source-file=\"LangfuseLogo.tsx\"/><h2 class=\"mt-5 text-center text-2xl font-bold leading-9 tracking-tight text-primary\">Loading<!-- --> ...</h2></div></div><script src=\"https://uptime.betterstack.com/widgets/announcement.js\" data-id=\"189328\" async=\"\" type=\"text/javascript\" data-sentry-component=\"BetterStackUptimeStatusMessage\" data-sentry-source-file=\"_app.tsx\"></script></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{\"statusCode\":404}},\"page\":\"/_error\",\"query\":{},\"buildId\":\"ths-eUPeeEuP005_wv51H\",\"nextExport\":true,\"isFallback\":false,\"gip\":true,\"locale\":\"en\",\"locales\":[\"en\"],\"defaultLocale\":\"en\",\"scriptLoader\":[]}</script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML=\"window.__CF$cv$params={r:'95014cdb59befcda',t:'MTc0OTk4MjQ2My4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);\";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body></html>"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "â€¢ Scenario_QA.csv â†’ 10ê±´ Async ì²˜ë¦¬(gpt-4o-mini)\n",
    "â€¢ í”„ë¡¬í”„íŠ¸: order_delivery/v1_0@stable (smart_cs)\n",
    "â€¢ ê²°ê³¼: data/01_order_delivery/answer_results/Scenario_QA_V1_gpt-4o-mini_<ts>.xlsx\n",
    "\"\"\"\n",
    "import asyncio, time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import nest_asyncio, pandas as pd\n",
    "from langfuse import Langfuse\n",
    "from openai import AsyncOpenAI\n",
    "from langfuse.decorators import langfuse_context\n",
    "from langfuse.decorators import observe\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# â”€â”€â”€ ê²½ë¡œ ì„¸íŒ… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "BASE = Path(\"../data/01_order_delivery\")\n",
    "RESULT_DIR = BASE / \"answer_results\"\n",
    "RESULT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# â”€â”€â”€ Langfuse / Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "lf  = Langfuse()\n",
    "PROMPT = lf.get_prompt(\"order_delivery/v1_0\", label=\"stable\").prompt  # <-- ë ˆì´ë¸” lookup\n",
    "\n",
    "# â”€â”€â”€ CSV ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "scenario = pd.read_csv(BASE / \"Scenario_QA.csv\")\n",
    "cust     = pd.read_csv(BASE / \"Customer_Info.csv\")\n",
    "addr     = pd.read_csv(BASE / \"Delivery_Address.csv\")\n",
    "order    = pd.read_csv(BASE / \"Order_Info.csv\")\n",
    "shipping = pd.read_csv(BASE / \"Shipping_Issue_Log.csv\")\n",
    "\n",
    "df = (\n",
    "    scenario\n",
    "    .merge(cust,  on=\"customer_id\", suffixes=(\"\", \"_cust\"), how=\"left\")\n",
    "    .merge(order, on=\"customer_id\", suffixes=(\"\", \"_order\"), how=\"left\")\n",
    "    .merge(addr, on=\"customer_id\", suffixes=(\"\", \"_addr\"), how=\"left\")\n",
    "    .merge(shipping, on=\"order_id\", suffixes=(\"\", \"_shipping\"), how=\"left\")\n",
    ")\n",
    "\n",
    "# â”€â”€â”€ LLM í˜¸ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MODEL  = \"gpt-4o-mini\"\n",
    "client = AsyncOpenAI()  # OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”\n",
    "\n",
    "@observe()\n",
    "async def call_llm(row):\n",
    "    prompt_input = {\n",
    "        \"question\":          row.question,\n",
    "        \"customer_id\":       row.customer_id,\n",
    "        \"customer_name\":     row.customer_name,\n",
    "        \"order_id\":          row.order_id,\n",
    "        \"product_name\":      row.product_name,\n",
    "        \"shipping_status\":   row.shipping_status,\n",
    "        \"last_update\":       row.last_update or \"\",\n",
    "        \"shipping_company\":  row.shipping_company or \"\",\n",
    "        \"tracking_number\":   row.tracking_number or \"\",\n",
    "        \"address_line1\":     row.address_line1,\n",
    "        \"city\":              row.city,\n",
    "        \"postal_code\":       row.postal_code,\n",
    "    }\n",
    "\n",
    "    # Langfuse trace (session metadata)\n",
    "    langfuse_context.update_current_trace(\n",
    "        name       = \"order_delivery\",\n",
    "        user_id    = row.customer_id,\n",
    "        session_id = row.scenario_id,\n",
    "        tags       = [\"V1\", \"smart_cs\"],\n",
    "        metadata   = {\"model\": MODEL},\n",
    "    )\n",
    "\n",
    "    # Langfuse Prompt í…œí”Œë¦¿ ë©”ì‹œì§€ â†’ ì‹¤ì œ messages ìƒì„±\n",
    "    rendered_messages = render_prompt(PROMPT, prompt_input)\n",
    "\n",
    "    start = time.perf_counter_ns()\n",
    "\n",
    "    # ì§ì ‘ OpenAI í˜¸ì¶œ\n",
    "    response = await client.chat.completions.create(\n",
    "        model       = MODEL,\n",
    "        messages    = rendered_messages,\n",
    "        temperature = 0.3,\n",
    "        max_tokens  = 350,\n",
    "    )\n",
    "\n",
    "    latency_ms = (time.perf_counter_ns() - start) / 1e6\n",
    "\n",
    "    return response.choices[0].message.content, latency_ms, response.usage.prompt_tokens, response.usage.completion_tokens\n",
    "\n",
    "async def main():\n",
    "    tasks   = [call_llm(row) for _, row in df.iterrows()]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    out = df.copy()\n",
    "    out[[\"answer\", \"latency_ms\", \"prompt_tokens\", \"completion_tokens\"]] = pd.DataFrame(results)\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_path = RESULT_DIR / f\"Scenario_QA_V1_gpt-4o-mini_{ts}.xlsx\"\n",
    "    out.to_excel(out_path, index=False)\n",
    "    print(f\"âœ… ê²°ê³¼ ì €ì¥: {out_path}\")\n",
    "\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bf5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
