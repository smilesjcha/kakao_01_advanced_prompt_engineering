{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3527062",
   "metadata": {},
   "source": [
    "# Session 2 — Prompt Engineering 실습 (V1)\n",
    "\n",
    "이 노트북은 *고급 프롬프트 엔지니어링* 실습용으로 준비되었습니다.  \n",
    "- **문제 정의 → V0 → V1 → V2** 순으로 단계별 개선 과정을 체험합니다.  \n",
    "- 오직 **`gpt‑4o‑mini`** 모델만 사용합니다.  \n",
    "- 실제 회사 데이터 대신 *샘플* 시나리오 3종(`order_delivery`, `refund`, `account_login`)을 사용합니다.  \n",
    "- 각 버전별 **응답 내용·지연 시간·비용**을 비교해 보세요.\n",
    "\n",
    "> 실습 결과는 개인별로 V0.x ~ V0.3 등의 버전을 추가하며 자유롭게 발전시키면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5142eb0",
   "metadata": {},
   "source": [
    "## 패키지 설치 (Colab 또는 로컬)\n",
    "\n",
    "필요한 경우 아래 셀을 실행하여 종속성을 설치하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca2fc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jinja2==3.1.5 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (3.1.5)\n",
      "Requirement already satisfied: numpy==2.2.3 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: openai==1.65.5 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 3)) (1.65.5)\n",
      "Collecting langfuse==2.60.5 (from -r ../requirements.txt (line 4))\n",
      "  Obtaining dependency information for langfuse==2.60.5 from https://files.pythonhosted.org/packages/e9/04/8d69112a6b24431bfdb257a2a394f0ab036e5be5dcf4cb3b15db43b367f6/langfuse-2.60.5-py3-none-any.whl.metadata\n",
      "  Downloading langfuse-2.60.5-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: openpyxl==3.1.5 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 5)) (3.1.5)\n",
      "Requirement already satisfied: pandas==2.2.3 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 6)) (2.2.3)\n",
      "Requirement already satisfied: notion-client==2.3.0 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 7)) (2.3.0)\n",
      "Requirement already satisfied: xlsxwriter==3.2.0 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: aiohttp==3.9.1 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 9)) (3.9.1)\n",
      "Requirement already satisfied: nest_asyncio==1.5.7 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 10)) (1.5.7)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in /opt/homebrew/lib/python3.10/site-packages (from -r ../requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2==3.1.5->-r ../requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (2.11.5)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/lib/python3.10/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from openai==1.65.5->-r ../requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/homebrew/lib/python3.10/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (2.2.1)\n",
      "Requirement already satisfied: idna<4.0,>=3.7 in /opt/homebrew/lib/python3.10/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: packaging<25.0,>=23.2 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (24.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/lib/python3.10/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (2.32.4)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /opt/homebrew/lib/python3.10/site-packages (from langfuse==2.60.5->-r ../requirements.txt (line 4)) (1.17.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/homebrew/lib/python3.10/site-packages (from openpyxl==3.1.5->-r ../requirements.txt (line 5)) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from pandas==2.2.3->-r ../requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas==2.2.3->-r ../requirements.txt (line 6)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.10/site-packages (from pandas==2.2.3->-r ../requirements.txt (line 6)) (2025.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (25.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (6.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (1.20.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (1.7.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp==3.9.1->-r ../requirements.txt (line 9)) (4.0.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from anyio<5,>=3.5.0->openai==1.65.5->-r ../requirements.txt (line 3)) (1.2.1)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.65.5->-r ../requirements.txt (line 3)) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.65.5->-r ../requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.65.5->-r ../requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.65.5->-r ../requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.65.5->-r ../requirements.txt (line 3)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.65.5->-r ../requirements.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sjcha/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r ../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests<3,>=2->langfuse==2.60.5->-r ../requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests<3,>=2->langfuse==2.60.5->-r ../requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /opt/homebrew/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp==3.9.1->-r ../requirements.txt (line 9)) (0.3.2)\n",
      "Downloading langfuse-2.60.5-py3-none-any.whl (275 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.4/275.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langfuse\n",
      "  Attempting uninstall: langfuse\n",
      "    Found existing installation: langfuse 2.59.7\n",
      "    Uninstalling langfuse-2.59.7:\n",
      "      Successfully uninstalled langfuse-2.59.7\n",
      "Successfully installed langfuse-2.60.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b33eb",
   "metadata": {},
   "source": [
    "## 환경 설정 및 공통 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2c7a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, asyncio, time\n",
    "import nest_asyncio, pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langfuse import Langfuse\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "USE_STUB = OPENAI_API_KEY is None\n",
    "langfuse = Langfuse()\n",
    "\n",
    "if USE_STUB:\n",
    "    print(\"🔧  Stub 모드: OPENAI_API_KEY 가 설정되지 않아 실제 API 호출 대신 더미 응답을 사용합니다.\")\n",
    "else:\n",
    "    from langfuse.openai import AsyncOpenAI\n",
    "    client = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 가격(USD / token)\n",
    "PRICING = {\"input\": 0.15/1_000_000, \"output\": 0.60/1_000_000}\n",
    "\n",
    "async def call_openai(system_prompt: str, user_prompt: str, model: str = \"gpt-4o-mini\"):\n",
    "    start = time.perf_counter_ns()\n",
    "    if USE_STUB:\n",
    "        await asyncio.sleep(0.05)  # 지연 시간 시뮬레이션\n",
    "        answer = f\"[STUB] '{user_prompt[:25]}...' 에 대한 예시 응답\"\n",
    "        prompt_tokens = len(system_prompt.split()) + len(user_prompt.split())\n",
    "        completion_tokens = 120\n",
    "    else:\n",
    "        resp = await client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "        )\n",
    "        answer = resp.choices[0].message.content.strip()\n",
    "        usage = resp.usage\n",
    "        prompt_tokens = usage.prompt_tokens\n",
    "        completion_tokens = usage.completion_tokens\n",
    "    latency_ms = (time.perf_counter_ns() - start) / 1_000_000\n",
    "    cost = prompt_tokens * PRICING[\"input\"] + completion_tokens * PRICING[\"output\"]\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"latency_ms\": latency_ms,\n",
    "        \"prompt_tokens\": prompt_tokens,\n",
    "        \"completion_tokens\": completion_tokens,\n",
    "        \"usd_cost\": cost,\n",
    "    }\n",
    "\n",
    "async def run_version(df: pd.DataFrame, version_name: str, build_system_prompt):\n",
    "    tasks = []\n",
    "    for _, row in df.iterrows():\n",
    "        tasks.append(call_openai(build_system_prompt(row), row['question']))\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    # 결과를 컬럼으로 병합\n",
    "    for idx, res in enumerate(results):\n",
    "        for key, val in res.items():\n",
    "            df.loc[idx, f\"{version_name}_{key}\"] = val\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc54e59",
   "metadata": {},
   "source": [
    "## 예시 시나리오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b45cc54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>주문한 상품이 배송 예정일을 지났는데 아직 도착하지 않았어요. 어떻게 확인하나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>반품 신청을 했는데 환불 처리가 언제 완료되나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>로그인 시도 시 2단계 인증 오류가 발생합니다. 어떻게 해결할 수 있나요?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario                                       question\n",
       "0  order_delivery  주문한 상품이 배송 예정일을 지났는데 아직 도착하지 않았어요. 어떻게 확인하나요?\n",
       "1          refund                    반품 신청을 했는데 환불 처리가 언제 완료되나요?\n",
       "2   account_login      로그인 시도 시 2단계 인증 오류가 발생합니다. 어떻게 해결할 수 있나요?"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios = [\n",
    "    {\"scenario\": \"order_delivery\", \"question\": \"주문한 상품이 배송 예정일을 지났는데 아직 도착하지 않았어요. 어떻게 확인하나요?\"},\n",
    "    {\"scenario\": \"refund\", \"question\": \"반품 신청을 했는데 환불 처리가 언제 완료되나요?\"},\n",
    "    {\"scenario\": \"account_login\", \"question\": \"로그인 시도 시 2단계 인증 오류가 발생합니다. 어떻게 해결할 수 있나요?\"},\n",
    "]\n",
    "df = pd.DataFrame(scenarios)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1589f884",
   "metadata": {},
   "source": [
    "## V0.0 — Zero‑Shot (System Prompt 없이 바로 질문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6ce598d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>V0_0_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>주문한 상품이 배송 예정일을 지나도 도착하지 않은 경우, 다음과 같은 방법으로 확인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>반품 신청 후 환불 처리 완료까지 소요되는 시간은 주로 다음과 같은 요소에 따라 달...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>2단계 인증 오류가 발생하는 경우, 다음과 같은 방법으로 문제를 해결할 수 있습니다...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario                                        V0_0_answer\n",
       "0  order_delivery  주문한 상품이 배송 예정일을 지나도 도착하지 않은 경우, 다음과 같은 방법으로 확인...\n",
       "1          refund  반품 신청 후 환불 처리 완료까지 소요되는 시간은 주로 다음과 같은 요소에 따라 달...\n",
       "2   account_login  2단계 인증 오류가 발생하는 경우, 다음과 같은 방법으로 문제를 해결할 수 있습니다..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sys_prompt_v0_0(row):\n",
    "    return \"\"\n",
    "\n",
    "await run_version(df, \"V0_0\", sys_prompt_v0_0)\n",
    "df[['scenario', 'V0_0_answer']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80fcc52",
   "metadata": {},
   "source": [
    "## V0.1 — Persona + Tone + Clear Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eb01104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>V0_1_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>안녕하세요, 고객님. 배송 예정일이 지나도 상품이 도착하지 않은 점 사과드립니다. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>고객님, 반품 신청 후 환불 처리에는 보통 3-7일 정도 소요됩니다. 반품 상품이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>안녕하세요. 2단계 인증 오류로 인해 불편을 드려 죄송합니다. 먼저, 인증 코드가 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario                                        V0_1_answer\n",
       "0  order_delivery  안녕하세요, 고객님. 배송 예정일이 지나도 상품이 도착하지 않은 점 사과드립니다. ...\n",
       "1          refund  고객님, 반품 신청 후 환불 처리에는 보통 3-7일 정도 소요됩니다. 반품 상품이 ...\n",
       "2   account_login  안녕하세요. 2단계 인증 오류로 인해 불편을 드려 죄송합니다. 먼저, 인증 코드가 ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sys_prompt_v0_1(row):\n",
    "    return (\n",
    "        \"You are a calm and professional Korean CS chatbot for an e‑commerce platform. \"\n",
    "        \"Answer politely in Korean, maximum 5 sentences.\"\n",
    "    )\n",
    "\n",
    "await run_version(df, \"V0_1\", sys_prompt_v0_1)\n",
    "df[['scenario','V0_1_answer']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306705c",
   "metadata": {},
   "source": [
    "## V0.2 — Few‑Shot + Chain‑of‑Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e385730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>V0_2_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>불편을 드려 죄송합니다. 주문하신 상품의 운송장 번호를 확인해 주시면 배송 상태를 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>반품 신청 후 환불 처리는 일반적으로 3~5일 소요됩니다. 반품 상품이 도착하고 검...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>2단계 인증 오류는 주로 입력한 전화번호와 인증 방법 설정의 불일치 혹은 일시적인 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario                                        V0_2_answer\n",
       "0  order_delivery  불편을 드려 죄송합니다. 주문하신 상품의 운송장 번호를 확인해 주시면 배송 상태를 ...\n",
       "1          refund  반품 신청 후 환불 처리는 일반적으로 3~5일 소요됩니다. 반품 상품이 도착하고 검...\n",
       "2   account_login  2단계 인증 오류는 주로 입력한 전화번호와 인증 방법 설정의 불일치 혹은 일시적인 ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_examples = \"\"\"\n",
    "<example>\n",
    "[고객] 주문한 상품이 아직 도착하지 않았어요!\n",
    "[챗봇] 불편을 드려 죄송합니다. 운송장 번호 123‑4567을 조회해 보니 현재 물류센터에 있습니다. 1~2일 내 도착 예정이며, 지연 시 바로 안내드리겠습니다.\n",
    "</example>\n",
    "\"\"\"\n",
    "\n",
    "def sys_prompt_v0_2(row):\n",
    "    return (\n",
    "        f\"{few_shot_examples}\\n\\n\"\n",
    "        \"You are a CS assistant. Think step‑by‑step to figure out the cause internally, \"\n",
    "        \"but provide only the final concise answer in Korean (max 5 lines).\"\n",
    "    )\n",
    "\n",
    "await run_version(df, \"V0_2\", sys_prompt_v0_2)\n",
    "df[['scenario','V0_2_answer']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da1030",
   "metadata": {},
   "source": [
    "## 버전별 비교 (Latency & Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce880de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>V0_0_latency_ms</th>\n",
       "      <th>V0_0_usd_cost</th>\n",
       "      <th>V0_1_latency_ms</th>\n",
       "      <th>V0_1_usd_cost</th>\n",
       "      <th>V0_2_latency_ms</th>\n",
       "      <th>V0_2_usd_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>order_delivery</td>\n",
       "      <td>5201.338833</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>1545.340375</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>1634.396875</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refund</td>\n",
       "      <td>8404.851375</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>1648.630500</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1440.019500</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account_login</td>\n",
       "      <td>5667.732541</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>2128.210834</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>3735.301250</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scenario  V0_0_latency_ms  V0_0_usd_cost  V0_1_latency_ms  \\\n",
       "0  order_delivery      5201.338833       0.000153      1545.340375   \n",
       "1          refund      8404.851375       0.000107      1648.630500   \n",
       "2   account_login      5667.732541       0.000199      2128.210834   \n",
       "\n",
       "   V0_1_usd_cost  V0_2_latency_ms  V0_2_usd_cost  \n",
       "0       0.000049      1634.396875       0.000072  \n",
       "1       0.000058      1440.019500       0.000050  \n",
       "2       0.000068      3735.301250       0.000066  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_cols = ['scenario']\n",
    "for v in ['V0_0','V0_1','V0_2']:\n",
    "    compare_cols += [f\"{v}_latency_ms\", f\"{v}_usd_cost\"]\n",
    "df[compare_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a01b92",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✍️ 개인 실습 영역\n",
    "\n",
    "아래 빈 셀을 복사하여 **V0.1 ~ V0.3** 등 자신만의 변형을 시도해 보세요.  \n",
    "- 새로운 System Prompt를 설계하거나  \n",
    "- Few‑Shot 예시 개수를 늘리거나  \n",
    "- ELI5, JSON 포맷 등 추가 요구사항을 넣어볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 여기에 개인 실습 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba01ef8",
   "metadata": {},
   "source": [
    "# 끝 🎉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84acbd8",
   "metadata": {},
   "source": [
    "## 작업한 V1.0 Prompt Langfuse에 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a75a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  당신은 30대 중반의 숙련된 전자상거래 배송 CS 담당자입니다.  \n",
      "  말투는 차분하고 전문적으로 유지하세요.  \n",
      "  \n",
      "  ### 내부 사고(Chain-of-Thought) 가이드 — 고객에게는 보이지 않도록!  \n",
      "  1. 질문에서 요구하는 정보가 주소 변경/배송 지연/운송장 등 어느 유형인지 분류  \n",
      "  2. CSV로 전달된 주문·주소·배송 상태를 단계별로 점검  \n",
      "  3. 해결 절차·예상 일정·재발 알림 등을 논리적으로 정리\n",
      "  \n",
      "  ### 최종 응답 형식 — 한국어 120단어 이내  \n",
      "  • 고객명 + 주문·상품·상태 요약  \n",
      "  • 다음 진행 단계 or 조치(숫자 목록 사용)  \n",
      "  • 마무리 문구: “추가 문의사항이 있으면 언제든 말씀해주세요.”\n",
      "\n",
      "  ### 질문\n",
      "  {{question}}\n",
      "  \n",
      "  ### 고객·주문 컨텍스트\n",
      "  ID: {{customer_id}}  이름: {{customer_name}}\n",
      "  주문번호: {{order_id}}  상품: {{product_name}}\n",
      "  배송상태: {{shipping_status}}  (최근 업데이트: {{last_update}})\n",
      "  택배사: {{shipping_company}}  송장: {{tracking_number}}\n",
      "  기본주소: {{address_line1}}, {{city}} {{postal_code}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while fetching prompt 'order_delivery/v1_0-label:production': status_code: 404, body: <!DOCTYPE html><html lang=\"en\"><head><meta charSet=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width\"/><meta name=\"next-head-count\" content=\"2\"/><link rel=\"preload\" href=\"/_next/static/css/08b3e129faadb9d6.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/08b3e129faadb9d6.css\" data-n-g=\"\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-42372ed130431b0a.js\"></script><script src=\"/_next/static/chunks/webpack-3493017210f8f3cb.js\" defer=\"\"></script><script src=\"/_next/static/chunks/framework-9e13880ebb429a2d.js\" defer=\"\"></script><script src=\"/_next/static/chunks/main-9c9c77a3987594f4.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_app-39a9ec525d0fcf02.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_error-d748218a48df77d2.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_buildManifest.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_ssgManifest.js\" defer=\"\"></script></head><body><div id=\"__next\"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class=\"flex min-h-full flex-1 flex-col justify-center py-12 sm:px-6 lg:px-8\" data-sentry-component=\"Spinner\" data-sentry-source-file=\"spinner.tsx\"><div class=\"sm:mx-auto sm:w-full sm:max-w-md\"><img src=\"/icon.svg\" width=\"42\" height=\"42\" alt=\"Langfuse Icon\" class=\"mx-auto motion-safe:animate-spin\" data-sentry-component=\"LangfuseIcon\" data-sentry-source-file=\"LangfuseLogo.tsx\"/><h2 class=\"mt-5 text-center text-2xl font-bold leading-9 tracking-tight text-primary\">Loading<!-- --> ...</h2></div></div><script src=\"https://uptime.betterstack.com/widgets/announcement.js\" data-id=\"189328\" async=\"\" type=\"text/javascript\" data-sentry-component=\"BetterStackUptimeStatusMessage\" data-sentry-source-file=\"_app.tsx\"></script></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{\"statusCode\":404}},\"page\":\"/_error\",\"query\":{},\"buildId\":\"ths-eUPeeEuP005_wv51H\",\"nextExport\":true,\"isFallback\":false,\"gip\":true,\"locale\":\"en\",\"locales\":[\"en\"],\"defaultLocale\":\"en\",\"scriptLoader\":[]}</script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML=\"window.__CF$cv$params={r:'95014c52ef02fcd8',t:'MTc0OTk4MjQ0MS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);\";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body></html>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Prompt created (v1.0)\n",
      "👀 Langfuse UI ▸ Prompts ▸ order_delivery 확인\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langfuse import Langfuse\n",
    "\n",
    "def parse_prompty(path: Path):\n",
    "    \"\"\"Langfuse-style .prompty → ChatPrompt 형태로 변환\"\"\"\n",
    "    content = path.read_text(encoding=\"utf-8\")\n",
    "    sections = content.strip().split('---')\n",
    "\n",
    "    if len(sections) < 3:\n",
    "        raise ValueError(\"❌ .prompty 파일은 YAML + system + user prompt 형식이어야 합니다.\")\n",
    "\n",
    "    _ = sections[1]\n",
    "    prompt_block = sections[2]\n",
    "\n",
    "    # 각 부분 추출\n",
    "    system_prompt = \"\"\n",
    "    user_prompt = \"\"\n",
    "    current_role = None\n",
    "    lines = prompt_block.strip().splitlines()\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip().startswith(\"system:\"):\n",
    "            current_role = \"system\"\n",
    "            continue\n",
    "        elif line.strip().startswith(\"user:\"):\n",
    "            current_role = \"user\"\n",
    "            continue\n",
    "\n",
    "        if current_role == \"system\":\n",
    "            system_prompt += line + \"\\n\"\n",
    "        elif current_role == \"user\":\n",
    "            user_prompt += line + \"\\n\"\n",
    "    \n",
    "    print(system_prompt)\n",
    "    print(user_prompt)\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
    "        {\"role\": \"user\", \"content\": user_prompt.strip()}\n",
    "    ]\n",
    "\n",
    "# Langfuse Prompt 등록\n",
    "lf = Langfuse()\n",
    "PROMPT_PATH = Path(\"../prompts/01_order_delivery/v1_0.prompty\")\n",
    "PROMPT_NAME = \"order_delivery/v1_0\"\n",
    "version = \"1.0\"\n",
    "\n",
    "chat_prompt = parse_prompty(PROMPT_PATH)\n",
    "\n",
    "try:\n",
    "    existing = lf.get_prompt(name=PROMPT_NAME, type=\"chat\")\n",
    "except Exception as e:\n",
    "    if \"404\" in str(e):\n",
    "        existing = None\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "if existing:\n",
    "    lf.update_prompt(\n",
    "        prompt_id = existing.id,\n",
    "        prompt    = chat_prompt,\n",
    "        tags      = [\"smart_cs\"],\n",
    "        labels    = [\"stable\"],\n",
    "    )\n",
    "    print(\"🔄 Prompt updated (v1.0)\")\n",
    "else:\n",
    "    lf.create_prompt(\n",
    "        name      = PROMPT_NAME,\n",
    "        type      = \"chat\",\n",
    "        prompt    = chat_prompt,\n",
    "        tags      = [\"smart_cs\"],\n",
    "        labels    = [\"stable\"],\n",
    "    )\n",
    "    print(\"✅ Prompt created (v1.0)\")\n",
    "\n",
    "print(\"👀 Langfuse UI ▸ Prompts ▸ order_delivery 확인\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13caf852",
   "metadata": {},
   "source": [
    "## 작업한 V1.0 Prompty 파일 불러와서, 시나리오 결과 돌리기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "325798ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "def render_prompt(messages: list, variables: dict) -> list:\n",
    "    \"\"\"Langfuse prompt template (list of dicts) → rendered OpenAI messages\"\"\"\n",
    "    rendered = []\n",
    "    for message in messages:\n",
    "        role = message[\"role\"]\n",
    "        content_template = message[\"content\"]\n",
    "        content = Template(content_template).render(**variables)\n",
    "        rendered.append({\"role\": role, \"content\": content})\n",
    "    return rendered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while fetching prompt 'order_delivery/v1_0-label:stable': status_code: 404, body: <!DOCTYPE html><html lang=\"en\"><head><meta charSet=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width\"/><meta name=\"next-head-count\" content=\"2\"/><link rel=\"preload\" href=\"/_next/static/css/08b3e129faadb9d6.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/08b3e129faadb9d6.css\" data-n-g=\"\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-42372ed130431b0a.js\"></script><script src=\"/_next/static/chunks/webpack-3493017210f8f3cb.js\" defer=\"\"></script><script src=\"/_next/static/chunks/framework-9e13880ebb429a2d.js\" defer=\"\"></script><script src=\"/_next/static/chunks/main-9c9c77a3987594f4.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_app-39a9ec525d0fcf02.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_error-d748218a48df77d2.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_buildManifest.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_ssgManifest.js\" defer=\"\"></script></head><body><div id=\"__next\"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class=\"flex min-h-full flex-1 flex-col justify-center py-12 sm:px-6 lg:px-8\" data-sentry-component=\"Spinner\" data-sentry-source-file=\"spinner.tsx\"><div class=\"sm:mx-auto sm:w-full sm:max-w-md\"><img src=\"/icon.svg\" width=\"42\" height=\"42\" alt=\"Langfuse Icon\" class=\"mx-auto motion-safe:animate-spin\" data-sentry-component=\"LangfuseIcon\" data-sentry-source-file=\"LangfuseLogo.tsx\"/><h2 class=\"mt-5 text-center text-2xl font-bold leading-9 tracking-tight text-primary\">Loading<!-- --> ...</h2></div></div><script src=\"https://uptime.betterstack.com/widgets/announcement.js\" data-id=\"189328\" async=\"\" type=\"text/javascript\" data-sentry-component=\"BetterStackUptimeStatusMessage\" data-sentry-source-file=\"_app.tsx\"></script></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{\"statusCode\":404}},\"page\":\"/_error\",\"query\":{},\"buildId\":\"ths-eUPeeEuP005_wv51H\",\"nextExport\":true,\"isFallback\":false,\"gip\":true,\"locale\":\"en\",\"locales\":[\"en\"],\"defaultLocale\":\"en\",\"scriptLoader\":[]}</script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML=\"window.__CF$cv$params={r:'95014cdb59befcda',t:'MTc0OTk4MjQ2My4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);\";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body></html>\n"
     ]
    },
    {
     "ename": "ApiError",
     "evalue": "status_code: 404, body: <!DOCTYPE html><html lang=\"en\"><head><meta charSet=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width\"/><meta name=\"next-head-count\" content=\"2\"/><link rel=\"preload\" href=\"/_next/static/css/08b3e129faadb9d6.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/08b3e129faadb9d6.css\" data-n-g=\"\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-42372ed130431b0a.js\"></script><script src=\"/_next/static/chunks/webpack-3493017210f8f3cb.js\" defer=\"\"></script><script src=\"/_next/static/chunks/framework-9e13880ebb429a2d.js\" defer=\"\"></script><script src=\"/_next/static/chunks/main-9c9c77a3987594f4.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_app-39a9ec525d0fcf02.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_error-d748218a48df77d2.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_buildManifest.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_ssgManifest.js\" defer=\"\"></script></head><body><div id=\"__next\"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class=\"flex min-h-full flex-1 flex-col justify-center py-12 sm:px-6 lg:px-8\" data-sentry-component=\"Spinner\" data-sentry-source-file=\"spinner.tsx\"><div class=\"sm:mx-auto sm:w-full sm:max-w-md\"><img src=\"/icon.svg\" width=\"42\" height=\"42\" alt=\"Langfuse Icon\" class=\"mx-auto motion-safe:animate-spin\" data-sentry-component=\"LangfuseIcon\" data-sentry-source-file=\"LangfuseLogo.tsx\"/><h2 class=\"mt-5 text-center text-2xl font-bold leading-9 tracking-tight text-primary\">Loading<!-- --> ...</h2></div></div><script src=\"https://uptime.betterstack.com/widgets/announcement.js\" data-id=\"189328\" async=\"\" type=\"text/javascript\" data-sentry-component=\"BetterStackUptimeStatusMessage\" data-sentry-source-file=\"_app.tsx\"></script></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{\"statusCode\":404}},\"page\":\"/_error\",\"query\":{},\"buildId\":\"ths-eUPeeEuP005_wv51H\",\"nextExport\":true,\"isFallback\":false,\"gip\":true,\"locale\":\"en\",\"locales\":[\"en\"],\"defaultLocale\":\"en\",\"scriptLoader\":[]}</script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML=\"window.__CF$cv$params={r:'95014cdb59befcda',t:'MTc0OTk4MjQ2My4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);\";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body></html>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/api/resources/prompts/client.py:100\u001b[0m, in \u001b[0;36mPromptsClient.get\u001b[0;34m(self, prompt_name, version, label, request_options)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundError(\n\u001b[0;32m--> 100\u001b[0m         pydantic_v1\u001b[38;5;241m.\u001b[39mparse_obj_as(typing\u001b[38;5;241m.\u001b[39mAny, \u001b[43m_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    101\u001b[0m     )  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    102\u001b[0m _response_json \u001b[38;5;241m=\u001b[39m _response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/httpx/_models.py:832\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjson\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjsonlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mApiError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# ─── Langfuse / Prompt ──────────────────────────────────────\u001b[39;00m\n\u001b[1;32m     23\u001b[0m lf  \u001b[38;5;241m=\u001b[39m Langfuse()\n\u001b[0;32m---> 24\u001b[0m PROMPT \u001b[38;5;241m=\u001b[39m \u001b[43mlf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morder_delivery/v1_0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mprompt  \u001b[38;5;66;03m# <-- 레이블 lookup\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# ─── CSV 로딩 ────────────────────────────────────────────────\u001b[39;00m\n\u001b[1;32m     27\u001b[0m scenario \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(BASE \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScenario_QA.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/client.py:1199\u001b[0m, in \u001b[0;36mLangfuse.get_prompt\u001b[0;34m(self, name, version, label, type, cache_ttl_seconds, fallback, max_retries, fetch_timeout_seconds)\u001b[0m\n\u001b[1;32m   1193\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1194\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptClient(\n\u001b[1;32m   1195\u001b[0m                     prompt\u001b[38;5;241m=\u001b[39mPrompt_Chat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfallback_client_args),\n\u001b[1;32m   1196\u001b[0m                     is_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1197\u001b[0m                 )\n\u001b[0;32m-> 1199\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached_prompt\u001b[38;5;241m.\u001b[39mis_expired():\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStale prompt \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m found in cache.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/client.py:1163\u001b[0m, in \u001b[0;36mLangfuse.get_prompt\u001b[0;34m(self, name, version, label, type, cache_ttl_seconds, fallback, max_retries, fetch_timeout_seconds)\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in cache or caching disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1161\u001b[0m )\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_prompt_and_update_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mttl_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_ttl_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounded_max_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfetch_timeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fallback:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/client.py:1275\u001b[0m, in \u001b[0;36mLangfuse._fetch_prompt_and_update_cache\u001b[0;34m(self, name, version, label, ttl_seconds, max_retries, fetch_timeout_seconds)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while fetching prompt \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/client.py:1262\u001b[0m, in \u001b[0;36mLangfuse._fetch_prompt_and_update_cache\u001b[0;34m(self, name, version, label, ttl_seconds, max_retries, fetch_timeout_seconds)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;129m@backoff\u001b[39m\u001b[38;5;241m.\u001b[39mon_exception(\n\u001b[1;32m   1248\u001b[0m     backoff\u001b[38;5;241m.\u001b[39mconstant, \u001b[38;5;167;01mException\u001b[39;00m, max_tries\u001b[38;5;241m=\u001b[39mmax_retries, logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m )\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_prompts\u001b[39m():\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mprompts\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url_encode(name),\n\u001b[1;32m   1253\u001b[0m         version\u001b[38;5;241m=\u001b[39mversion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1260\u001b[0m     )\n\u001b[0;32m-> 1262\u001b[0m prompt_response \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_prompts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompt_response\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1265\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m ChatPromptClient(prompt_response)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/backoff/_sync.py:105\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m details \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: target,\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melapsed\u001b[39m\u001b[38;5;124m\"\u001b[39m: elapsed,\n\u001b[1;32m    102\u001b[0m }\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    107\u001b[0m     max_tries_exceeded \u001b[38;5;241m=\u001b[39m (tries \u001b[38;5;241m==\u001b[39m max_tries_value)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/client.py:1251\u001b[0m, in \u001b[0;36mLangfuse._fetch_prompt_and_update_cache.<locals>.fetch_prompts\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;129m@backoff\u001b[39m\u001b[38;5;241m.\u001b[39mon_exception(\n\u001b[1;32m   1248\u001b[0m     backoff\u001b[38;5;241m.\u001b[39mconstant, \u001b[38;5;167;01mException\u001b[39;00m, max_tries\u001b[38;5;241m=\u001b[39mmax_retries, logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m )\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_prompts\u001b[39m():\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_url_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeout_in_seconds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfetch_timeout_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1259\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/langfuse/api/resources/prompts/client.py:104\u001b[0m, in \u001b[0;36mPromptsClient.get\u001b[0;34m(self, prompt_name, version, label, request_options)\u001b[0m\n\u001b[1;32m    102\u001b[0m     _response_json \u001b[38;5;241m=\u001b[39m _response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response_json)\n",
      "\u001b[0;31mApiError\u001b[0m: status_code: 404, body: <!DOCTYPE html><html lang=\"en\"><head><meta charSet=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width\"/><meta name=\"next-head-count\" content=\"2\"/><link rel=\"preload\" href=\"/_next/static/css/08b3e129faadb9d6.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/08b3e129faadb9d6.css\" data-n-g=\"\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-42372ed130431b0a.js\"></script><script src=\"/_next/static/chunks/webpack-3493017210f8f3cb.js\" defer=\"\"></script><script src=\"/_next/static/chunks/framework-9e13880ebb429a2d.js\" defer=\"\"></script><script src=\"/_next/static/chunks/main-9c9c77a3987594f4.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_app-39a9ec525d0fcf02.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_error-d748218a48df77d2.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_buildManifest.js\" defer=\"\"></script><script src=\"/_next/static/ths-eUPeeEuP005_wv51H/_ssgManifest.js\" defer=\"\"></script></head><body><div id=\"__next\"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class=\"flex min-h-full flex-1 flex-col justify-center py-12 sm:px-6 lg:px-8\" data-sentry-component=\"Spinner\" data-sentry-source-file=\"spinner.tsx\"><div class=\"sm:mx-auto sm:w-full sm:max-w-md\"><img src=\"/icon.svg\" width=\"42\" height=\"42\" alt=\"Langfuse Icon\" class=\"mx-auto motion-safe:animate-spin\" data-sentry-component=\"LangfuseIcon\" data-sentry-source-file=\"LangfuseLogo.tsx\"/><h2 class=\"mt-5 text-center text-2xl font-bold leading-9 tracking-tight text-primary\">Loading<!-- --> ...</h2></div></div><script src=\"https://uptime.betterstack.com/widgets/announcement.js\" data-id=\"189328\" async=\"\" type=\"text/javascript\" data-sentry-component=\"BetterStackUptimeStatusMessage\" data-sentry-source-file=\"_app.tsx\"></script></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{\"statusCode\":404}},\"page\":\"/_error\",\"query\":{},\"buildId\":\"ths-eUPeeEuP005_wv51H\",\"nextExport\":true,\"isFallback\":false,\"gip\":true,\"locale\":\"en\",\"locales\":[\"en\"],\"defaultLocale\":\"en\",\"scriptLoader\":[]}</script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML=\"window.__CF$cv$params={r:'95014cdb59befcda',t:'MTc0OTk4MjQ2My4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);\";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body></html>"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "• Scenario_QA.csv → 10건 Async 처리(gpt-4o-mini)\n",
    "• 프롬프트: order_delivery/v1_0@stable (smart_cs)\n",
    "• 결과: data/01_order_delivery/answer_results/Scenario_QA_V1_gpt-4o-mini_<ts>.xlsx\n",
    "\"\"\"\n",
    "import asyncio, time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import nest_asyncio, pandas as pd\n",
    "from langfuse import Langfuse\n",
    "from openai import AsyncOpenAI\n",
    "from langfuse.decorators import langfuse_context\n",
    "from langfuse.decorators import observe\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ─── 경로 세팅 ────────────────────────────────────────────────\n",
    "BASE = Path(\"../data/01_order_delivery\")\n",
    "RESULT_DIR = BASE / \"answer_results\"\n",
    "RESULT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ─── Langfuse / Prompt ──────────────────────────────────────\n",
    "lf  = Langfuse()\n",
    "PROMPT = lf.get_prompt(\"order_delivery/v1_0\", label=\"stable\").prompt  # <-- 레이블 lookup\n",
    "\n",
    "# ─── CSV 로딩 ────────────────────────────────────────────────\n",
    "scenario = pd.read_csv(BASE / \"Scenario_QA.csv\")\n",
    "cust     = pd.read_csv(BASE / \"Customer_Info.csv\")\n",
    "addr     = pd.read_csv(BASE / \"Delivery_Address.csv\")\n",
    "order    = pd.read_csv(BASE / \"Order_Info.csv\")\n",
    "shipping = pd.read_csv(BASE / \"Shipping_Issue_Log.csv\")\n",
    "\n",
    "df = (\n",
    "    scenario\n",
    "    .merge(cust,  on=\"customer_id\", suffixes=(\"\", \"_cust\"), how=\"left\")\n",
    "    .merge(order, on=\"customer_id\", suffixes=(\"\", \"_order\"), how=\"left\")\n",
    "    .merge(addr, on=\"customer_id\", suffixes=(\"\", \"_addr\"), how=\"left\")\n",
    "    .merge(shipping, on=\"order_id\", suffixes=(\"\", \"_shipping\"), how=\"left\")\n",
    ")\n",
    "\n",
    "# ─── LLM 호출 ───────────────────────────────────────────────\n",
    "MODEL  = \"gpt-4o-mini\"\n",
    "client = AsyncOpenAI()  # OPENAI_API_KEY 환경변수 필요\n",
    "\n",
    "@observe()\n",
    "async def call_llm(row):\n",
    "    prompt_input = {\n",
    "        \"question\":          row.question,\n",
    "        \"customer_id\":       row.customer_id,\n",
    "        \"customer_name\":     row.customer_name,\n",
    "        \"order_id\":          row.order_id,\n",
    "        \"product_name\":      row.product_name,\n",
    "        \"shipping_status\":   row.shipping_status,\n",
    "        \"last_update\":       row.last_update or \"\",\n",
    "        \"shipping_company\":  row.shipping_company or \"\",\n",
    "        \"tracking_number\":   row.tracking_number or \"\",\n",
    "        \"address_line1\":     row.address_line1,\n",
    "        \"city\":              row.city,\n",
    "        \"postal_code\":       row.postal_code,\n",
    "    }\n",
    "\n",
    "    # Langfuse trace (session metadata)\n",
    "    langfuse_context.update_current_trace(\n",
    "        name       = \"order_delivery\",\n",
    "        user_id    = row.customer_id,\n",
    "        session_id = row.scenario_id,\n",
    "        tags       = [\"V1\", \"smart_cs\"],\n",
    "        metadata   = {\"model\": MODEL},\n",
    "    )\n",
    "\n",
    "    # Langfuse Prompt 템플릿 메시지 → 실제 messages 생성\n",
    "    rendered_messages = render_prompt(PROMPT, prompt_input)\n",
    "\n",
    "    start = time.perf_counter_ns()\n",
    "\n",
    "    # 직접 OpenAI 호출\n",
    "    response = await client.chat.completions.create(\n",
    "        model       = MODEL,\n",
    "        messages    = rendered_messages,\n",
    "        temperature = 0.3,\n",
    "        max_tokens  = 350,\n",
    "    )\n",
    "\n",
    "    latency_ms = (time.perf_counter_ns() - start) / 1e6\n",
    "\n",
    "    return response.choices[0].message.content, latency_ms, response.usage.prompt_tokens, response.usage.completion_tokens\n",
    "\n",
    "async def main():\n",
    "    tasks   = [call_llm(row) for _, row in df.iterrows()]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    out = df.copy()\n",
    "    out[[\"answer\", \"latency_ms\", \"prompt_tokens\", \"completion_tokens\"]] = pd.DataFrame(results)\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_path = RESULT_DIR / f\"Scenario_QA_V1_gpt-4o-mini_{ts}.xlsx\"\n",
    "    out.to_excel(out_path, index=False)\n",
    "    print(f\"✅ 결과 저장: {out_path}\")\n",
    "\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bf5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
